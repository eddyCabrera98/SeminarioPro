{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab5CleanData.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "87TXvqhn7BIM",
        "colab_type": "code",
        "outputId": "ca822846-68f3-4be2-f44b-84b86a7cde29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, Bidirectional, LSTM, Dropout, Conv1D, MaxPooling1D, GRU\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "#dark mode\n",
        "#plt.rc_context({'xtick.color':'w', 'ytick.color':'w', 'text.color':'w', 'axes.labelcolor':'w'})\n",
        "\n",
        "seed=1234\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvnEuWAu7i0t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pip install kaggle --upgrade"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSwk7G5W8WCn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.environ['KAGGLE_USERNAME'] = \"eddyalexander\"\n",
        "os.environ['KAGGLE_KEY'] = \"fab67faf55645fb739e4a709ab71791c\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Wtj1Fw_8YRj",
        "colab_type": "code",
        "outputId": "d9030376-100a-4071-d143-8c0d845a38fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "#https://www.kaggle.com/extralime/math-lectures\n",
        "!kaggle datasets download extralime/math-lectures"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "math-lectures.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wf-hTsQj8aSU",
        "colab_type": "code",
        "outputId": "6f1f31a8-8cdc-436f-9705-bb51d385456d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "!unzip -o 'math-lectures.zip'"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  math-lectures.zip\n",
            "  inflating: raw_text.csv            \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzO6qjdb8f56",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "a105f4a9-a14a-4ae6-9922-a2d83265949e"
      },
      "source": [
        "os.listdir()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config', 'math-lectures.zip', 'raw_text.csv', 'sample_data']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqIwjEnpZYPB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mapping(label):\n",
        "     return dictionary[label.decode(\"utf-8\")];\n",
        "  #  return tf.Variable(dictionary[label.decode(\"utf-8\")], tf.int16)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1FQDFWLC2Ic",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encode(text_tensor, label):\n",
        "  encoded_text = encoder.encode(text_tensor.numpy()[0])\n",
        "  return encoded_text, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1lvOY_bYGnz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encode_map_fn(text, label):\n",
        "  # py_func doesn't set the shape of the returned tensors.\n",
        "  encoded_text, label = tf.py_function(encode, \n",
        "                                       inp=[text, label], \n",
        "                                       Tout=(tf.int64, tf.int64))\n",
        "  # `tf.data.Datasets` work best if all components have a shape set\n",
        "  #  so set the shapes manually: \n",
        "  encoded_text.set_shape([None])\n",
        "  label.set_shape([])\n",
        "  return encoded_text, label\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BYhVPE6YXiF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def toTensorDataset(dataset):\n",
        "  labels = dataset.pop('label')\n",
        "  tensor_dataset = tf.data.Dataset.from_tensor_slices((dataset.values,labels.values))\n",
        "  return tensor_dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSUWpyCoXKFO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# labels = lectures.pop('label')\n",
        "# #Build Dataset\n",
        "# dataset = tf.data.Dataset.from_tensor_slices((lectures.values,labels.values))\n",
        "# #Check Dataset\n",
        "# for feat, targ in dataset.take(5):\n",
        "#   print ('Features: {}, Target: {}'.format(feat, targ))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfZPKCVT8lUj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lectures = pd.read_csv('raw_text.csv')\n",
        "classNames = lectures['label'].unique()\n",
        "# text = lectures['text'];\n",
        "BUFFER_SIZE = 5000\n",
        "BATCH_SIZE = 8\n",
        "TAKE_SIZE = 5000\n",
        "dictionary = {};\n",
        "for i, cn in enumerate(classNames, start=1):\n",
        "   dictionary[cn] = i\n",
        "dictionary\n",
        "\n",
        "dictionary = {\n",
        "    'Probability': 0,\n",
        "    'Linear Algebra': 1\n",
        "}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbizB90pFhox",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "03af4211-f290-4347-a344-82e3a2c142b3"
      },
      "source": [
        "for name in classNames:\n",
        "  print('{}, {}'.format(name, lectures[lectures['label'] == name]['text'].count()))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calculus, 70\n",
            "Probability, 124\n",
            "CS, 104\n",
            "Algorithms, 81\n",
            "Diff. Eq., 93\n",
            "Linear Algebra, 152\n",
            "AI, 48\n",
            "Statistics, 79\n",
            "Math for Eng., 28\n",
            "Data Structures, 62\n",
            "NLP, 19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0HPXNDZHghc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "chosen_ClassNames = ['Probability', 'Linear Algebra']\n",
        "lectures = lectures[lectures['label'].isin(chosen_ClassNames)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJ17qCp_HUNt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lectures = lectures.replace({\"label\":dictionary})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JC1zHxqKZV-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lectures['label'] = lectures['label'].astype(str).astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVUThV090jR0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "outputId": "873b3395-4b08-4e59-8fcd-47c7e24abd2f"
      },
      "source": [
        "lectures.info()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 276 entries, 1 to 857\n",
            "Data columns (total 2 columns):\n",
            "text     276 non-null object\n",
            "label    276 non-null int64\n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 6.5+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzU6zDFwa2Wc",
        "colab_type": "text"
      },
      "source": [
        "#Split Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ws1Sgo_haeD9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, test = train_test_split(lectures, test_size=0.2)\n",
        "# train, val = train_test_split(train, test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFV1SzFv4iIK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "1309bcc9-a694-421c-b7f3-7f492a124b9c"
      },
      "source": [
        "print(\"Train count: {}\".format(train.count()))\n",
        "#print(\"Val Count: {}\".format(val.count()))\n",
        "print(\"Test Count: {}\".format(test.count()))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train count: text     220\n",
            "label    220\n",
            "dtype: int64\n",
            "Test Count: text     56\n",
            "label    56\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_UW19pDW--r",
        "colab_type": "code",
        "outputId": "c261404d-9d93-437d-a2bc-d0cab07cec80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        }
      },
      "source": [
        "print(\"Train dataset\")\n",
        "train.info()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train dataset\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 220 entries, 137 to 673\n",
            "Data columns (total 2 columns):\n",
            "text     220 non-null object\n",
            "label    220 non-null int64\n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 5.2+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5v3FOVUXamp",
        "colab_type": "code",
        "outputId": "6f932527-e5d6-4e26-bc61-c5058b1f6044",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        }
      },
      "source": [
        "print(\"Test dataset\")\n",
        "test.info()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test dataset\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 56 entries, 305 to 604\n",
            "Data columns (total 2 columns):\n",
            "text     56 non-null object\n",
            "label    56 non-null int64\n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 1.3+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CAZfvzkXdhT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(\"Validation dataset\")\n",
        "# val.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NhHzgxTZl1F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TensorFlow Dataset\n",
        "train = toTensorDataset(train)\n",
        "test =  toTensorDataset(test)\n",
        "#val =  toTensorDataset(val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cd1IzuXWZ_tw",
        "colab_type": "code",
        "outputId": "e4b83698-4ea2-49ae-ce4a-f36660ccddff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        }
      },
      "source": [
        "for feat, targ in test.take(5):\n",
        "  print ('Features: {}, Target: {}'.format(feat, targ))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Features: [b\"The following content is\\nprovided under a Creative Commons license. Your support will help MIT\\nOpenCourseWare continue to offer high quality educational\\nresources for free. To make a donation, or to view\\nadditional materials from hundreds of MIT courses, visit\\nMIT OpenCourseWare at ocw.mit.edu. PROFESSOR: Now, today\\nwe are continuing with this last unit. Unit 5, continued. The informal title of this unit\\nis Dealing With Infinity. That's really the extra little\\npiece that we're putting in to our discussions of things like\\nlimits and integrals. To start out with today, I'd\\nlike to recall for you, L'Hopital's Rule. And in keeping with the spirit\\nhere, we're just going to do the infinity / infinity case. I stated this a little\\ndifferently last time, and I want to state it again today. Just to make clear what the\\nhypotheses are and what the conclusion is. We start out with, really,\\nthree hypotheses. Two of them are kind\\nof obvious. The three hypotheses are that\\nf (x) tends to infinity, g ( x) tends to infinity, that's\\nwhat it means to be in this infinity / infinity case. And then the last assumption\\nis that f ' ( x) / g ' (x), tends to a limit, L. And this\\nis all as x tends to some a. Some limit a. And then the conclusion is that\\nf( x) / g ( x) also tends to L, as x goes to a. Now, so that's the way it is. So it's three limits. But presumably these are\\nobvious, and this one is exactly what we were going\\nto check anyway. Gives us this one limit. So that's the statement. And then the other little\\ninteresting point here, which is consistent with this idea of\\ndealing with infinity, is that a equals plus or minus\\ninfinity and L equals plus or minus infinity are OK. That is, the numbers capital L,\\nthe limit capital L and the number a can also be infinite. Now in recitation yesterday,\\nyou should have discussed something about rates of growth,\\nwhich follow from what I said in lecture last time and\\nalso maybe from some more detailed discussions that\\nyou had in recitation. And I'm going to introduce a\\nnotation to compare functions. Namely, we say that f ( x) is\\na lot less than g ( x). So this means that the limit,\\nas it goes to infinity, this tends to 0. As x goes to infinity,\\nthis would be. So this is a notation, a new\\nnotation for us. f is a lot less than g. And it's meant to be read\\nonly asymptotically. It's only in the limit\\nas x goes to infinity that this happens. And implicitly here, I'm always\\nassuming that these are positive quantities. f\\nand g are positive. What you saw in recitation was\\nthat you can make a systematic comparison of all the standard\\nfunctions that we know about. For example, the ln function\\ngoes to infinity. But a lot more slowly\\nthan x to a power. A lot more slowly then e^ x. A lot more slowly than,\\nsay, e ^ x ^2. So this one is slow. This one is moderate. And this one is fast.\\nAnd this one is very fast. Going to infinity. Tends to infinity, and\\nthis is of course as x goes to infinity. All of them go to infinity, but\\nat quite different rates. And, analogous to this, and\\ntoday we're going to be doing this, needing to do this quite\\na bit, is rates of decay, which are more or less the\\nopposite of rates of growth. So rates of decay are rates\\nat which things tend to 0. So the rate of decay, and for\\nthat I'm just going to take reciprocals of these numbers. So 1 / ln x tends to 0. But rather slowly. It's much bigger\\nthan 1 / x ^ p. Oh, I didn't mention that\\nthis exponent p is meant to be positive. That's a convention that I'm\\nusing without saying. I should've told you that. So think x ^ 1/2, x ^ 1, x ^2,\\nthey're all in this sort of moderate intermediate range. And then that, in turn, goes to\\n0 but much more slowly then 1 / e ^ x, also known\\nas e^ - x. And that, in turn, this guy\\nhere goes to 0 incredibly fast. e ^ - x ^2 vanishes\\nreally, really fast. So this is a review of the\\nL'Hopital's Rule. What we said last time, and the\\napplication of it, which is to rates of growth and tells\\nus what these rates of growth are. Today, I want to talk about\\nimproper integrals. And improper integrals, we've\\nalready really seen one or two of them on your exercises. And we mention them a\\nlittle bit, briefly. I'm just going to go through\\nthem more carefully and more systematically now. And we want to get just exactly\\nwhat's going on with these rates of decay and\\ntheir relationship with improper integrals. So I need for you to understand\\non the spectrum of the range of functions like\\nthis, which ones are suitable for integration as x\\ngoes to infinity. Well, let's start out\\nwith the definition. The integral from a to infinity\\nof f(x) dx is, by definition the limit as n goes\\nto infinity of the ordinary definite integral up to some\\nfixed, finite level. That's the definition. And there's a word that we use\\nhere, which is that we say the integral, so this is terminology\\nfor it, converges if the limit exists. And diverges if not. Well, these are the key\\nwords for today. So here's the issue that we're\\ngoing to be addressing. Which is whether the limit\\nexists or not. In other words, whether\\nthe integral converges or diverges. These notions have a geometric\\nanalog, which you should always be thinking of at\\nthe same time in the back of your head. I'll draw a picture of the\\nfunction Here it's starting out at a. And maybe it's going\\ndown like this. And it's interpreting\\nit geometrically. This would only work\\nif f is positive. Then the convergent\\ncase is the case where the area is finite. So the total area is finite\\nunder this curve. And the other case is the\\ntotal area is infinite. I claim that both of these\\nthings are possible. Although this thing goes on\\nforever, if you stop it at one stage, n, then of course\\nit's a finite number. But as you go further and\\nfurther and further, there's more and more and more area. And there are two\\npossibilities. Either as you go all the way\\nout here to infinity, the total that you get adds\\nup to a finite total. Or else, maybe there's\\ninfinitely much. For instance, if it's a straight\\nline going across, there's clearly infinitely\\nmuch area underneath. So we need to do a bunch\\nof examples. And that's really our main job\\nfor the day, and to make sure that we know exactly what\\nto expect in all cases. The first example is the\\nintegral from 0 to infinity of e^ - kx dx. Where k is going to be\\nsome positive number. Some positive constant. This is the most fundamental,\\nby far, of the definite integrals. Improper integrals. And in order to handle this, the\\nthing that I need to do is to check the integral from\\n0 up to n. e ^ - kx dx. And since this is an easy\\nintegral to evaluate, we're going to do it. It's - 1 / k e ^ - kx, that's\\nthe antiderivative. Evaluated at 0 and n. And that, if I plug in these\\nvalues, is - 1 / k, e^ - k N. Minus, and if I evaluate it at\\n0, I get a (- 1 / k) e^ 0. So there's the answer. And now we have to think\\nabout what happens as n goes to infinity. So as n goes to infinity, what's\\nhappening is the second term here stays unchanged. But the first term is e to\\nsome negative power. And the exponent is getting\\nlarger and larger. That's because k is\\npositive here. You've definitely got\\nto pay attention. Even though I'm doing this with\\ngeneral variables here, you've got to pay attention\\nto signs of things. Because otherwise you'll always\\nget the wrong answer. So you have to pay very\\nclose attention here. So this is, if you like, e ^\\nminus infinity in the limit, which is 0. And so in the limit, this\\nthing tends to 0. And this thing is just\\nequal to 1 / k. And so all told, the answer\\nis 1 / k And that's it. Now we're going to abbreviate\\nthis a little bit. This thought process, you're\\ngoing to have to go through every single time you do this. But after a while you also get\\ngood enough at it that you can make it a little bit\\nless cluttered. So let me show you a shorthand\\nfor this same calculation. Namely, I write 0 to infinity\\ne ^ - kx dx. And that's equal to - 1 / k\\ne ^ - kx 0 to infinity. That was cute. Not small enough, however. So, here we are. We have the same calculation\\nas we had before. But now we're thinking, really,\\nin our minds that this infinity is some very,\\nvery enormous number. And we're going to plug it in. And you can either do this\\nin your head or not. You say - 1 / k e^ - infinity. Here's where I've used the\\nfact that k is positive. Because e ^ - k times a large\\nnumber is minus infinity. And then here + 1\\n/ k - (- 1 / k). Let me write it the same\\nway I did before. And that's just equal to 0 + 1\\n/ k, which is what we want. So this is the same calculation,\\njust slightly abbreviated. Yeah. Question. STUDENT: [INAUDIBLE] PROFESSOR: Good question. The question is, what\\nabout the case when the limit is infinity? I'm distinguishing between\\nsomething existing and its limit being infinity here. Whenever I make a discussion\\nof limits, I say a finite limit, or in this case, it works\\nfor infinite limits. So in other words, when\\nI say exists, I mean exists and is finite. So here, when I say that it\\nconverges and I say the limit exists, what I mean is that\\nit's a finite number. And so that's indeed\\nwhat I said here. The total area is finite. And, similarly, over here. I might add, however, that\\nthere is another part of this subject. Which I'm skipping entirely. Which is a little bit subtle. Which is the following. If f changes sign, there can\\nbe some cancellation and oscillation. And then sometimes the limit\\nexists, but the total area, if you counted it all positively,\\nis actually still infinite. And we're going to\\navoid that case. We're we're just going to treat\\nthese positive cases. So don't worry about\\nthat for now. That's the next layer of\\ncomplexity which we're not addressing in this class. Another question. STUDENT: [INAUDIBLE] PROFESSOR: The question is,\\nwould this be OK on tests. The answer is, absolutely yes. I want to encourage\\nyou to do this. If you can think about\\nit correctly. The subtle point is\\njust, you have to plug in infinity correctly. Namely, you have to realize\\nthat this only works if k is positive. This is the step where you're\\nplugging in infinity. And I'm letting you put this\\ninfinity up here as an endpoint value. So in fact that's exactly\\nthe theme. The theme is dealing\\nwith infinity here. And I want you to be able\\nto deal with it. That's my goal. STUDENT: [INAUDIBLE] PROFESSOR: OK, so another\\nquestion is, so let's be sure here when the limit exists,\\nI say it has to be finite. That means it's finite,\\nnot infinite. The limit can be 0. It can also be - 1. It can be anything. Doesn't have to be a\\npositive number. Other questions. So we've had our\\nfirst example. And now I just want to add one\\nphysical interpretation here. This is Example 1,\\nif you like. And this is something that was\\non your problem set, remember. That we talked about the\\nprobability, or the number, if you like, the number of\\nparticles on average that decay in some radioactive\\nsubstance. Say, in time between 0 and some\\ncapital T. And then that would be this integral, 0 to\\ncapital T, some total quantity times this integral here. This is the typical kind\\nof radioactive decay number that one gets. Now, in the limit, so this is\\nsome number of particles. If the substance is radioactive,\\nthen in the limit, we have this. Which is equal to the total\\nnumber of particles. And that's something that's\\ngoing to be important for normalizing and understanding. How much does the whole\\nsubstance, how many moles do we have of this stuff. What is it. And so this is a number that\\nis going to come up. Now, I emphasize that this\\nnotion of T going to infinity is just an idealization. We don't really believe that\\nwe're going to wait forever for this substance to decay. Nevertheless, as theorists, we\\nwrite down this quantity. And we use it. All the time. Furthermore, there's other good\\nreasons for using it, and why physicists accept\\nit immediately. Even though it's not really\\ncompletely physically realistic ever to let\\ntime go very, very far into the future. And the reason is, if you notice\\nthis answer here, look at how much simpler this number\\nis, 1 / k, than the numbers that I got in the\\nintermediate stages here. These are all ugly, the\\nlimits are simple. And this is a theme that\\nI've been trying to emphasize all semester. Namely, that the infinitesimal,\\nthe things that you get when you do\\ndifferentiation, are the easier formulas. The algebraic ones, the things\\nin the process of getting to the limit, are the ugly ones. These are the easy ones, these\\nare the hard ones. So in fact, infinity is\\nbasically easier than any finite number. And a lot of appealing formulas\\ncome from those kinds of calculations. Another question. STUDENT: [INAUDIBLE] PROFESSOR: The question is,\\nshouldn't the answer be a? Well, the answer turns\\nout to be a / k. Which means that when you set\\nup your arithmetic, and you model this to a collection\\nof particles. So you said it should be a. But that's because you\\nmade an assumption. Which was that a was the total\\nnumber of particles. But that's just false, right? This is the total number\\nof particles. So therefore, if you want to set\\nit up, you want set up so that this number's the total\\nnumber of particles. And that's how you set up a\\nmodel is, you do all the calculations and you see what\\nit's coming out to be. And that's why you need to do\\nthis kind of calculation. OK, so. The main thing is, you shouldn't\\nmake assumptions about models. You have to follow what the\\ncalculations tell you. They're not lying. OK, so now. We carried this out. There's one other example which\\nwe talked about earlier in the class. And I just wanted to\\nmention it again. It's probably the most famous\\nafter this one. Namely, the integral from minus\\ninfinity to infinity of e^ - x ^2 dx. Which turns out, amazingly, to\\nbe able to be evaluated. It turns out to be the\\nsquare root of pi. So this one is also great. This is the constant which\\nallows you to compute all kinds of things in\\nprobability. So this is a key number\\nin probability. It basically is the key to\\nunderstanding things like standard deviation and basically\\nany other thing in the subject of probability. It's also what's driving these\\npolls that tell you within 4% accuracy we know that\\npeople are going to vote this way or that. So in order to interpret all of\\nthose kinds of things, you need to know this number. And this number was only\\ncalculated numerically starting in the 1700s or so by\\npeople who, actually, by one guy whose name was de Moivre,\\nwho was selling his services to various royalty who were\\nrunning lotteries. In those days they ran\\nlotteries, too. And he was able to tell them\\nwhat the chances were of the various games. And he worked out this number. He realized that this\\nwas the pattern. Although he didn't know that it\\nwas the square root of pi, he knew it to sufficient\\naccuracy that he could tell them the correct answer to how\\nmuch money their lotteries would make. And of course we do this\\nnowadays, too. In all kinds of ways. Including slightly more legit\\nbusinesses like insurance. So now, I I'm going to give\\nyou some more examples. And and the other examples are\\nmuch more close to the edge between infinite and finite. This distinction between\\nconvergence and divergence. And let me just, maybe I'll say\\none more word about why we care about this very gross issue\\nof whether something is finite or infinite. When you're talking about\\nsomething like this normal curve here, there's an issue of\\nhow far out you have to go before you can ignore\\nthe rest. So we're going to ignore what's\\ncalled the tail here. Somehow you want to know that\\nthis is negligible. And you want to know how\\nnegligible it is. And this is the job of a\\nmathematician, is to know what finite region you have to\\nconsider and which one you're going to carefully calculate\\nnumerically. And then the rest, you're going\\nto have to take care of by some theoretical reasoning. You're going to have to know\\nthat these tails are small enough that they don't matter\\nin your finite calculation. And so, we care very much\\nabout the tails. Because they're the only\\nthing that the machine won't tell us. So that's the part that\\nwe have to know. And these tails are also\\nsomething which are discussed all the time in financial\\nmathematics. They're very worried\\nabout fat tails. That is, unlikely events that\\nnevertheless happen sometimes. And they get burned fairly\\nregularly with them. As they have recently, with\\nthe mortgage scandal. So, these things are pretty\\nserious and they really are spending a lot of\\ntime on them. Of course, there are lots of\\nother practical issues besides just the mathematics. But you've got to get\\nthe math right, too. So we're going to now talk about\\nsome borderline cases for these fat tails. Just how fat do they have to be\\nbefore they become infinite and overwhelm the\\ncentral bump. So we'll save this for\\njust a second. And what I'm saving up here is\\nthe borderline case, which I'm going to concentrate on, which\\nis this moderate rate, which is x to powers. Here's our next example. I guess we'll call\\nthis Example 3. It's the integral from\\n1 to infinity dx / x. That's the power p = 1. And this turns out to be\\na borderline case. So it's worth carrying\\nout carefully. Now, again I'm going to do\\nit by the slower method. Rather than the shorthand\\nmethod. But ultimately, you can\\ndo it by the short method if you'd like. I break it up into an integral\\nthat goes up to some large number, n. I see that its logarithm\\nfunction is the antiderivative. And so what I get is ln n\\n- ln 1, which is just 0. So this is just log n. In any case, it tends\\nto infinity as n goes to infinity. So the conclusion is, since the\\nlimit is infinite, that this thing diverges. Now, I'm going to do this\\nsystematically now with all powers p, to see what happens. I'll look at the integral. Sorry, I'm going to have\\nto start at 1 here. From 1 to infinity, dx\\n/ x ^p, and see what happens with these. And you'll see that p = 1 is\\na borderline when I do this calculation. This time I'm going to do the\\ncalculation the hard way. But now you're going to have to\\nthink and pay attention to see what it is that I'm doing. First of all, I'm going to\\ntake the antiderivative. And this is x ^ - p, so it's\\n- p + 1 / - p + 1. That's the antiderivative of\\nthe function 1 / x ^ - p. And then I have to evaluate\\nthat at 1 and infinity. So now, I'll write this down. But I'm going to be particularly\\ncareful here. I'll write it down. It's infinity to the -\\np + 1 / - p + 1 -, so I plug in 1 here. So I get 1 / - p + 1. So this is what I'm getting. Again, what you should be\\nthinking here is this is a very large number\\nto this power. Now, there are two cases. There are two cases. And they exactly\\nsplit at p = 1. When p = 1, this number is 0. This exponent is 0, and in fact\\nthis expression doesn't make any sense because the\\ndenominator is also 0. But for all of the\\nother values, the denominator makes sense. But what's going on is that\\nthis is infinite when this exponent is infinity to\\na positive power. And it's 0 when it's infinity\\nto a negative power. So I'm going to say it\\nhere, and you must check this at home. Because this is exactly what\\nI'm going to ask you about on the exam. This is it. This type of thing, maybe with\\na specific value of p here. When p &lt; 1, this thing\\nis infinite. On the other hand, when p\\n&gt; 1, this thing is 0. So when p &gt; 1, this\\nthing is 0. It's just equal to 0. And so the answer\\nis 1 / p - 1. Because that's this number. Minus the quantity\\n1 / - p + 1. This is a finite number here. Notice that the answer would\\nbe weird if this thing went away in the p &lt; 1 case. Then it would be a\\nnegative number. It would be a very strange\\nanswer to this question. So, in fact that's\\nnot what happens. What happens is that the answer\\ndoesn't make sense. It's infinite. So let me just write this\\ndown again, under here. This is a test in a\\nparticular case. And here's the conclusion. Ah. No, I'm sorry. I think I was going to write\\nit over on this board here. So the conclusion is that the\\nintegral from 1 to infinity dx / x^p diverges if p &lt;= 1. And converges if p &gt; 1. And in fact, we can actually\\nevaluate it. It's equal to 1 / p - 1. It's got a nice, clean\\nformula even. Alright, now let\\nme remind you. So I didn't spell the word\\ndiverges right, did I? Oh no, that's an r. I guess that's right. Diverges if p &lt;= 1. So really, I needed both of\\nthese arguments, which are sitting above it in\\norder to do it. Because the second argument\\ndidn't work at all when p = 1 because the formula for the\\nantiderivative is wrong. The formula for the\\nantiderivative is given by the ln function when p = 1. So I had to do this\\ncalculation too. This is the borderline case,\\nbetween p &gt; 1 and p &lt; 1. When p &gt; 1, we got\\nconvergence. We could calculate\\nthe integral. When p &lt; 1, when we got\\ndivergence and we calculated the integral over there. And here in the borderline case,\\nwe got a logarithm. and we also got divergence. So it failed at the edge. Now, this takes care\\nof all the powers. Now, there are a number of\\ndifferent things that one can deduce from this. And let me carry them out. So this is more or less\\nthe second thing that you'll want to do. And I'm going to emphasize\\nmaybe one aspect of it. I guess we'll get rid of this. But it's still the issue that\\nwe're discussing here. Is whether this area\\nis fat or thin. I'll remind you of that. So here's the next idea. Something called limit\\ncomparison. Limit comparison is what you're\\ngoing to use when, instead of being able actually\\nto calculate the number, you don't yet know what\\nthe number is. But you can make a comparison to\\nsomething whose convergence properties you already\\nunderstand. Now, here's the statement. If a function, f, is similar to\\na function, asymptotically the same as a function, g, as\\nx goes to infinity, I'll remind you what that\\nmeans in a second. Then the integral starting at\\nsome point out to infinity of f(x) dx, and the other\\none, converge and diverge at the same time. So both, either, either\\n-- sorry, let's try it the other way. Either, both. Either both converge,\\nor both diverge. They behave exactly\\nthe same way. In terms of whether they're\\ninfinite or not. And, let me remind you what\\nthis tilde means. This thing means that f(\\nx) / g ( x) tends to 1. So if you have a couple of\\nfunctions like that, then their behavior is the same. This is more or less obvious. It's just because far enough\\nout, this is for large a, if you like. We're not paying any attention\\nto what happens. It just has to do with the tail,\\nand after a while f ( x) and g(x) are comparable\\nto each other. So their integrals are\\ncomparable to each other. So let's just do a couple\\nof examples here. If you take the integral from 0\\nto infinity dx / the square root of x ^2 + 10, then I claim\\nthat the square root of x^2 + 10 resembles the square\\nroot of x ^2, which is just x. So this thing is going\\nto be like. So now I'm going to have to\\ndo one thing to you here. Which is, I'm going to\\nchange this to 1. To infinity. dx /x And the\\nreason is that this x = 0 is extraneous. Doesn't have anything to\\ndo with what's going on with this problem. This guy here, the piece of it\\nfrom, so we're going to ignore the part integral from 0 to 1 dx\\n/ square root of x ^2 + 10, which is finite anyway. And unimportant. Whereas, unfortunately, the\\nintegral of dx will have a singularity at x = 0. So we can't make the\\ncomparison there. Anyway, this one is infinite. So this is divergence. Using what I knew from before. Yeah. STUDENT: [INAUDIBLE] PROFESSOR: The question is, why\\ndid we switch from 0 to 1? So I'm going to say a little\\nbit more about that later. But let me just make\\nit a warning here. Which is that this guy here is\\ninfinite for other reasons. Unrelated reasons. The comparison that we are\\ntrying to make is with the tail as x goes to infinity. So another way of saying this\\nis that I should stick an a here and an a here and\\nstay away from 0. So, say a = 1. If I make these both 1,\\nthat would be OK. If I make them both 2,\\nthat would be OK. If I make them both 100,\\nthat would be OK. So let's leave it as\\n100 right now. And it's acceptable. I want you to stay away\\nfrom the origin here. Because that's another\\nbad point. And just talk about what's\\nhappening with the tail. So this is a tail, and I\\nalso had a different name for it up top. Which is emphasizing this. Which is limit comparison. It's only what's happening at\\nthe very end of the picture that we're interested in. So again, this is as\\nx goes to infinity. That's the limit we're talking\\nabout, the limiting behavior. And we're trying not to pay\\nattention to what's happening for small values of x. So to be consistent, if I'm\\ngoing to do it up to 100 I'm ignoring what's happening up\\nto the first 100 values. In any case, this\\nguy diverged. And let me give you\\nanother example. This one, you could\\nhave computed. This one you could have\\ncomputed, right? Because it's a square root of\\nquadratic, so there's a trig substitution that evaluates\\nthis one. The advantage of this limit\\ncomparison method is, it makes no difference whether you can\\ncompute the thing or not. You can still decide whether\\nit's finite or infinite, fairly easily. So let me give you an\\nexample of that. So here we have another\\nexample. We'll take the integral dx\\n/ square root of x^3 + 3. Let's say, for the\\nsake of argument. From 0 to infinity. Let's leave off, let's make it\\n10 to infinity, whatever. Now this one is problematic\\nfor you. You're not going to be able\\nto evaluate it, I promise. So on the other hand 1 / the\\nsquare root of x^3 + 3 is similar to 1 / the square root\\nof x ^3, which is 1 / x ^ 3/2. So this thing is going to\\nresemble this integral here. Which is convergent. According to our rule. So those are the, more or less\\nthe main ingredients. Let me just mention one other\\nintegral, which was the one that we had over here. This one here. If you look at this integral, of\\ncourse we can compute it so we know the area is finite. But the way that you would\\nactually carry this out, if you didn't know the number and\\nyou wanted to check that this integral were finite, then you\\nwould make the following comparison. This one is not so difficult. First of all, you would write it\\nas twice the integral from 0 to infinity of e^ - x ^2 dx. This is a new example here, and\\nwe're just checking for convergence only. Not evaluation. And now, I'm going to make a\\ncomparison here, Rather than a limit, comparison I'm actually\\njust going to make an ordinary comparison. That's because this thing\\nvanishes so fast. It's so favorable that we can only put\\nsomething on top of it, we can't get something underneath\\nit that exactly balances with it. In other words, this wiggle was\\nsomething which had the same growth rate as the\\nfunction involved. This thing just vanishes\\nincredibly fast. It's great. It's too good for us,\\nfor this comparison. So instead what I'm going\\nto make is the following comparison. e ^ - x\\n^2 &lt; = e ^ - x. At least for x &gt;= 1. When x &gt; = 1, then x ^2 &gt;=\\nx, and so - x ^2 &lt; - x. And so e^ - x^2 is\\nless than this. So this is the reasoning\\ninvolved. And so what we have here\\nis two pieces. We have 2, the integral from\\n0 to 1, of e^ - x ^2. That's just a finite part. And then we have this other\\npart, which I'm going to replace with the e ^ - x here. 2 times 1 to infinity\\ne ^ -x dx. So this is, if you like,\\nthis is ordinary comparison of integrals. It's something that we did way\\nat the beginning of the class. Or much earlier on, when we were\\ndealing with integrals. Which is that if you have a\\nlarger integrand, then the integral gets larger. So we've replaced\\nthe integral. We've got the same integrand\\non 0 to 1. And we have a larger integrand\\non, so this one is larger integrand. And this one we know\\nis finite. This one is a convergent\\nintegral. So the whole business\\nis convergent. But of course we replaced it\\nby a much larger thing. So we're not getting the right\\nnumber out of this. We're just showing that\\nit converges. So these are the main\\ningredients. As I say, once the thing gets\\nreally, really fast decaying, it's relatively straightforward. There's lots of room to show\\nthat it converges. Now, there's one last item of\\nbusiness here which I have to promise you. Which I promised you, which had\\nto do with dealing with this bottom piece here. So I have to deal with what\\nhappens when there's a singularity. This is known as an improper\\nintegral of the second type. And the idea of these examples\\nis the following. You might have something\\nlike this. Something like this. Or something like this. These are typical sorts\\nof examples. And before actually describing\\nwhat happens, I just want to mention. So first of all, the key point\\nhere is you can just calculate these things. And plug in 0 and it works and\\nyou'll get the right answer. So you'll determine, you'll\\nfigure out, that it turns out that this one will converge,\\nthis one will diverge, and this one will diverge. That's what will turn\\nout to happen. However, I want to warn you that\\nyou can fool yourself. And so let me give you a\\nslightly different example. Let's consider this\\nintegral here. The integral from -\\n1 to 1 dx / x ^2. If you carry out this integral\\nwithout thinking, what will happen is, you'll get the\\nantiderivative, which is - x ^ -1, evaluated at - 1 and 1. And you plug it in. And what do you get? You get - 1 (1 ^ - 1) -,\\nuh-oh. (- ( -1) ^ - 1). There's a lot of - 1's\\nin this problem. OK, so that's - 1. And this one, if you work it all\\nout, as I sometimes don't get the signs right, but this\\ntime I really paid attention. It's - 1, I'm telling you\\nthat's what it is. So that comes out to be - 2. Now, this is ridiculous. This function here\\nlooks like this. It's positive, right? 1 / x ^2 is positive. How exactly is it that the area\\nbetween - 1 and 1 came out to be a negative number? That can't be. There was clearly something\\nwrong with this. And this is the kind of thing\\nthat you'll get regularly if you don't pay attention to\\nconvergence of integrals. So what's going on here is\\nactually that this area in here is infinite. And this calculation that\\nI made is nonsense. So it doesn't work. This is wrong. Because it's divergent. Actually, when you get to\\nimaginary numbers, it'll turn out that there's a way\\nof rescuing it. But, still, it means something\\ntotally different when that integral is thought\\nto be at - 2. So. What I want you to do here, so\\nI think we'll have to finish this up very briefly\\nnext time. We'll do these three\\ncalculations and you'll see that these two guys\\nare divergent and this one converges. And we'll do that next time.\"], Target: 1\n",
            "Features: [b\"In our previous lesson, we saw what\\nprefix and postfix expressions are but we did not discuss how we can\\nevaluate these expressions. In this lesson we'll see how we can\\nevaluate prefix and postfix expressions. Algorithms to evaluate prefix and\\npostfix expressions are similar but I'm going to talk about postfix\\nevaluation first because its easier to understand and\\nimplement and then I'll talk about evaluation of\\nprefix. Okay so let's get started. I have written an expression in infix form\\nhere and I first want to convert this to  postfix form. As we know in infix form  operator is\\nwritten in between operands and we want to convert to postfix in\\nwhich operator is written after operands. We have already seen how we can do\\nthis in our previous lesson. We need to go step by step just the way we would go in  evaluation of infix. We need to go in\\norder of precedence and in each step we need to identify operands of an operator and we need to\\nbring the operator in front of the operands. What we can\\nactually do is we can first resolve operator precedence and put\\nparenthesis at appropriate places. In this expression\\nwe will first do this multiplication this first\\nmultiplication then we'll do this second multiplication then we will perform this addition and\\nfinally the subtraction. Okay now we will go one\\noperator at a time, operands for this multiplication\\noperator are 'A' and 'B'. So this A*B will become AB*. Now next we would need to look at this\\nmultiplication this will transform to cd* and now we can do the change for this addition the two operands are these two expressions in postfix, so I'm placing the plus\\noperator after these two expressions. Finally for this last operator the operands are this complex expression\\nand this variable 'e'. So this is how we will look like after the transformation. Finally when we \\nare done with all the operators we can get rid of all the paranthesis. They're not needed in postfix expression. This is how you can do the conversion\\nmanualy. We will discuss efficient ways of doing this programitically in later lessons. We will discuss algorithms to   convert infix to prefix or postfix in later lessons. In this lesson we're\\nonly going to look at algorithms to evaluate prefix and\\npostfix expressions. Okay so we have this postfix\\nexpression here and we want to evaluate this expression,\\nlet's say for these values of variables a,b,c,d and e. So we have this expression in\\nterms of values to evaluate. I'll first quickly tell you how you can\\nevaluate a postfix expression manually. What you need to do is you need to scan\\nthe expression from left to right and find the first occurrence of an\\noperator like here, multiplication is the first operator.\\nIn postfix expression operands of an operator will always\\nlie to its left. For the first operator, the preceding two\\nentities will always be operands. You need to look for the first\\noccurrence of this pattern operand, operand, operator in the expression \\nand now you can apply the operator on these two operands and reduced expression. So this is\\nwhat I'm getting after evaluating 23*. Now we need to repeat this\\nprocess till we are done with all the operators. Once again we need to\\nscan the expression from left to right and look for the first operator, if the\\nexpression is correct it will be preceeded by two values. So basically we need to look for first\\noccurrence of this pattern operand, operand, operator. So now we can reduce this. we have 6 and then we have 5*4  20. We are using space as delimeter here, there should be some space in between two operands. Okay so this is\\nwhat I have now. Once again I'll look for the first\\noccurrence of operand, operand and operator. We will go on like this till we are done with all the operators. When I am saying we need to look for first\\noccurrence of this pattern operand, operand and operator, what I mean by operand here is a value and\\nnot a complex expression itself. The first\\noperator will always be preceded by two values and if you will give this some thought you will\\nbe able to understand why. If you can see in this expression we are\\napplying the operators in the same order in which we have them while\\nparsing from left to right. So first we're applying this leftmost\\nmultiplication on 2 and 3 then we are applying the next\\nmultiplication on 5 and 4 then we're performing the addition and then finally we are performing the\\nsubtraction and whenever we are performing an operation, we're picking the last two operands proceeding the operator in the\\nexpression. So if we have to do this programitically,\\nif we have to evaluate a postfix expression given to us in a string like this and let's say operands and operators are separated by space we can have some\\nother delimiter like comma also to separate operands\\nand operator. Now what we can do is we can parse the\\nstring from left to right. In each step in this parsing, in each\\nstep in the scanning process, we can get a token that will either be an\\noperator or an operand. What we can do is as we parse from left to right, we can keep track\\nof all the operands seen so far and I'll come back to how it\\nwill help us. So I'm keeping all the operands so seen so\\nfar in a list. The first entity that we have here is 2 which is an operand so it will go to the\\nlist, next we have 3 which once again is operand so it will go into the list next we have this multiplication\\noperator. Now this multiplication should be applied to last two operands preceding it last\\ntwo operands to the left of it because we already have the elements stored in this list. All we need to do is we need to pick the\\nlast two from this list and perform the operation. It should be 2*3 and with this multiplication we have reduced expression this 23* has now become 6 it has become an operand that can be used by an operator later. We are at this stage right now that I'm\\nshowing in the right. I'll continue the scanning. Next we have an operand, will push this number 5 on to the\\nlist. Next we have 4 which once again will\\ncome to the list and now we have the multiplication operator and it should be applied to the last two\\noperands in the reduced expression and we should put the result back into the list. This is the stage\\nwhere we are right now. So this list actually is storing all the\\noperands in the reduced expression preceeding the position at which we are during passing. Now for this edition we should take out\\nthe last two elements from the list and then we should put the result back,\\nnext we have an operand we are at this stage right now. Next we have\\nan operator this subtraction. We will perform this\\nsubtraction and put the result back. Finally when I'm done\\nscanning the whole expression I'll have only one element left in the list and this will be my final answer this\\nwill be my final result. This is an efficient algorithm. We\\nare doing only one pass on the string representing the expression and we have our result. The list that we are using here if you could notice is being used in a\\nspecial way we are inserting operands one at a time\\nfrom one side and then to perform an operation we are\\ntaking out operand from the same side. Whatever is coming in last is getting\\nout first. This whole thing that we're doing here\\nwith the list can be done efficiently with a stack, which is nothing but a\\nspecial kind of list in which elements are inserted and removed from the same side in which\\nwhatever gets in last comes out first. It's called Last In First\\nOut(LIFO) structure. Let's do this evaluation again. I have drawn\\nlogical representation of stack here, and this time I'm going to use this stack. \\nI'll also write pseudo code for this algorithm. I'm going to write a function named evaluate postfix that will take a string\\nas argument. Let's name this string expression exp for expression. In my function here, i'll first create a stack. Now for the sake of simplicity, let's assume that each operand or operator\\nin the expression will be of only one character. So to get a token or operator,\\nWe can simply run a loop from zero till length of expression -1. So exp[i] will be my operand or operator. If\\nexpression 'i' is operand I should put, push it onto the stack\\nelse if exp[i] is operator we should do two pop operations in the\\nstack store the value of the operands in some variable. I'm using variable names op1 and op2. Let's say this pop function will remove\\nan element from top of stack s and also return this element. Once we have the two operands we can perform the operation, I'm using this\\nvariable to store the output. Let's say this function will perform the operation. Now the result should be pushed back onto the stack. If\\nI have to run through this expression with whatever code I have right now,\\nthen first entity is 2 which is operand so it should be pushed onto the stack.\\nNext we have 3, once again this will go to the stack.\\nNext we have this multiplication operator. So we will come to this else if part of\\nthe code. I'll make first pop and I'll store 3 in this variable op1. Well actually this is the second operand,\\nso I should say this one is op2 and next one will be op1. Once I have popped these two elements I can perform the\\noperation. As you can see I'm doing the same stuff that I was doing with the list, the only thing is that I'm showing\\nthings vertically. Stack is being shown as a vertical list. I'm\\ninserting or taking out from the top. Now I'll push the result back onto the\\nstack. Now we will move to the next entity\\nwhich is operand it will go onto the stack. Next 4 will\\nalso go onto the stack and now we have this multiplication, so we\\nwill perform two pop operations. After this operation\\nis performed result will be pushed back. Next we have\\naddition. So we will go on like this. We have 26\\npushed onto the stack now. Now it's 9 which will go in and\\nfinally we have this subtraction 26-9, 17 will be pushed onto the stack. At this stage we will be done with the loop we are done with all the tokens, all the\\noperands and operators. The top of stack can be returned as\\nfinal result. At this stage we will have only one\\nelement in the stack and this element will be my final result.\\nYou will have to take care of some parsing logic in actual implementation.\\nOperand can be a number of multiple digits and then we will have delimiter like\\nspace or comma so you'll have to take care of that.\\nParsing operand or operator will be some task. If you want to see my implementation you\\ncan check the description of this video for a link. Okay so this was postfix evaluation.\\nLet's now quickly see how we can do prefix evaluation. Once again I have written this expression in\\ninfix form and I'll first convert it to prefix. We will go in order of precedence. I first\\nput this paranthesis this 2 * 3 will become *23, this 5 * 4 will become *54 and now we will pick this plus(+) operator whose operands are these two prefix expressions. Finally for the subtraction operator this is\\nthe first operand and this is the second operand. In the last step we can get rid of all the\\nparenthesis. So this is what I have finally. Let's now\\nsee how we can evaluate a prefix expression like this. We will do it just like postfix this time all we need to do is we need\\nto scan from right, so we will go from right to left. Once again we will people use a stack if it's an\\noperand we can push it onto the stack. So here for this example 9 will go onto the stack and now we will go to the next entity in the left, it's 4. Once again we have an operand. It will go onto the stack. Now we have 5. 5 will also be pushed onto the stack and\\nnow we have this multiplication operator. At this stage we need to pop two elements from the stack. This time the first element popped will be the first operand. In postfix the first element popped was \\nthe second operand. This time the second element popped will\\nbe the second operand. For this multiplication, first operand is 5 and second operand is 4. This order is really important for multipication the order doesn't matter but for say division or subtraction this will matter. Result 20 will be pushed onto the stack and we\\nwill keep moving left. Now we have 3 and 2 both will go onto the stack and now we have this multiplication operation. 3 and 2 will be popped and their product 6 will be pushed. Now we have this addition, the two\\nelements at top are 20 and 6 they will be popped and their sum 26 will be pushed. Finally we have to subtraction. 26 and 9 will be popped out and 17 will be\\npushed and finally this is my answer. Prefix evaluation can be performed in couple of other ways also but this\\nis easiest and most straightforward. Okay so this was prefix\\nand postfix evaluation using Stack. In coming lessons, we will see efficient algorithms to convert infix to prefix or postfix. This is it\\nfor this lesson. Thanks for Watching!\"], Target: 1\n",
            "Features: [b'The following content is\\nprovided under a Creative Commons license. Your support will help\\nMIT OpenCourseWare continue to offer high quality\\neducational resources for free. To make a donation or\\nview additional materials from hundreds of MIT courses,\\nvisit MIT OpenCourseWare at ocw.mit.edu. PROFESSOR: Just a reminder,\\ndrop day is tomorrow. So if you were thinking\\nabout dropping the course or in danger of a bad\\ngrade or something, tomorrow\\'s the last\\nchance to bail out. Last time we began our\\ndiscussion on probability with the Monty Hall game--\\nthe Monty Hall problem. And as part of the analysis,\\nwe made assumptions of the form that given that\\nCarol placed the prize in box 1, the probability that\\nthe contestant chooses box 1 is 1/3. Now, this is an\\nexample of something that\\'s called a\\nconditional probability. And that\\'s what we\\'re\\ngoing to study today. Now, in general,\\nyou have something like the conditional\\nprobability that an event, A, happens given that some\\nother event, B, has already taken place. And you write that down as\\na probability of A given B. And both A and B are events. Now, the example\\nfrom Monty Hall-- and actually, we had\\nseveral-- but you might have B being\\nthe event that Carol places the prize in box 1. And A might be the event that\\nthe contestant chooses box 1. And we assumed for\\nthe Monty Hall game that the probability of\\nA given B in this case was 1/3 third because\\nthe contestant didn\\'t know where the prize was. Now in general, there\\'s\\na very simple formula to compute the probability\\nof A given B. In fact, we\\'ll treat it as a definition. Assuming the probability of B\\nis non-zero than the probability of A given B is just the\\nprobability of A and B happening, both happening,\\ndivided by the probability of B happening. And you can see why this makes\\nsense when the picture-- say this is our sample space. And let this be the\\nevent, A, and this be the event, B. Now we\\'re\\nconditioning on the fact that B happened. Now once we\\'ve\\nconditioned on that, all this stuff outside of\\nB is no longer possible. All those outcomes are no longer\\nin the space of consideration. The only outcomes left\\nare in B. So in some sense we\\'ve shrunk the\\nsample space to be B. And all we care about is the\\nprobability that A happens inside this new sample space. And that is, we\\'re asking the\\nprobability 1 of these outcomes happens given that this\\nis the sample space. Well, this is just A\\nintersect B because you still have to have A happen, but\\nnow you\\'re inside of B. And then we divide\\nby probability of B. So we normalize this\\nto be probability one. OK. Because we\\'re\\nsaying B happened-- we\\'re conditioning on that. Therefore, the probability\\nof these outcomes must be 1. So we divide by the probability\\nof B. So we normalize. This now becomes-- the\\nprobability of A given B is this share of B\\nweighted by the outcomes. OK. All right. For example then, what\\'s the\\nprobability of B given B? what\\'s that equal? 1. OK. Because we said it happened-- so\\nit happens with probability 1. Or, using the formula, that\\'s\\njust probability of B and B divided by probability\\nof B. Well, that equals the probability\\nof B divided by the probability\\nof B, which is 1. All right. Any questions about\\nthe definition of the conditional probability? Very simple. And it\\'s easy to work\\nwith using the formulas. Now, there\\'s a nice\\nrule called the product rule, which follows from\\nthe definition very simply. The product rule says that\\nthe probability of A and B for two events is equal\\nto the probability of B times the probability\\nof A given B. And that\\'s just follow\\nstraightforwardly from this definition. Just multiply by probability\\nof B on both sides. All right. So now you have a\\nrule of computing a probability of two events\\nsimultaneously happening. So for example, in the\\nMonty Hall problem, what\\'s the probability\\nthat Carol places the prize in box one and that\\'s\\nthe box the contestant chooses? All right? So if we took A and B\\nas defined up there, that\\'s the probability that\\nCarol places it in box one and the contestant chose it. Well, that\\'s the probability\\nthat the contestant chooses it is 1/3 times the probability\\nthat Carol put it there, given the contestant chose\\nit, or actually, vice versa, Is 1/9. OK? And this extends to more events. It is called the\\ngeneral product rule. So if you want to compute\\nthe probability of A1 and A2 and all the way up to An, that\\'s\\nsimply the probability of a 1 happening all by itself times\\nthe probability of A2 given A1 times-- well, I\\'ll do the next\\none-- times the probability of A3 given A1 and A2, dot,\\ndot dot, times, finally, the probability of An\\ngiven all the others. So that starts to look a\\nlittle more complicated. But it gives you a handy way\\nof computing the probability that an intersection\\nof events takes place. I do This is proved by induction\\non n, just taking that rule and using induction on n. It\\'s not hard. But we won\\'t go through it. All right. Let\\'s do some examples. We\\'ll start with an easy one. Say you\\'re playing\\na playoff series and you\\'re going to\\nplay best 2 out of 3. All right. So you have a best\\n2 out of 3 series. So whoever wins the first two\\ngames, best two out of three wins. And say you\\'re told that\\nthe probability of winning the first game is 1/2. So the teams are matched\\n50-50 for the first game. But then you\\'re told that the\\nprobability of winning a game after a victory is higher. It\\'s 2/3. So the probability of\\nwinning immediately after a game following\\na win is two thirds. And similarly, the probability\\nof winning after a loss is 1/3. All right. And the idea here is\\nthat you win a game, you\\'re sort of psyched,\\nyou\\'ve got momentum, and going into the next day\\nyou\\'re more likely to win. Similarly, if you lost\\nyou\\'re sort of down and the other guy has a\\nbetter chance of beating you. Now, what we\\'re going\\nto try to figure out is the probability\\nof winning the series given you won the first game. All right? Now, conditional\\nprobability comes up in two places in this problem. Anybody tell me places\\nwhere it\\'s come up? So I got the problem statement\\nand the that\\'s the goal is to figure out the probability\\nyou win the series given you won the first game. So what\\'s one place\\nconditional probability is entering into this problem? Yeah? AUDIENCE: The\\nprobability changes depending on the result\\nof the previous game. PROFESSOR: That\\'s true. The probability of winning\\nany particular game is influenced by\\nthe previous game. So you\\'re using conditional\\nprobability there. All right. And where else? Yeah. AUDIENCE: [INAUDIBLE]\\nyou have to take into account [INAUDIBLE]. PROFESSOR: That\\'s interesting. That will be another question\\nwe\\'re going to look at. What\\'s the probability\\nof playing three games? Yep. That\\'s one. OK. Well, the question\\nwe\\'re after, what\\'s the probability of\\nwinning the series given that you won the first game. We\\'re going to compute a\\nconditional probability there. So it\\'s coming up in a\\ncouple of places here. All right. Let\\'s figure this out. It\\'s easy to do given\\nthe tree method. So let\\'s make the tree for this. So we have possibly three games\\nthere\\'s game one, game two, and game three. Game one, you can win or lose. There\\'s two branches. Game two you can win or lose. And now, game three-- well, it\\ndoesn\\'t even take place here. But it does here. You can win or lose here. And you could win or lose here. And here the series is over. So there is no game\\nthree in that case. The probabilities are\\nnext we put a probability of every branch here. Game one is 50-50. What\\'s the probability\\nyou take this branch? 2/3, because you\\'re on the path\\nwhere you won the first game. You win the second\\ngame with 2/3. You lose with 1/3. Now here you\\'re on the path\\nwhere you lost the first game. So this has 1/3\\nand this has 2/3. All right? And then lastly, what\\'s\\nthe probability I have the win on the third game here? 1/3, because I just\\nlost the last game. That\\'s all I\\'m conditioning on. So that becomes 1/3. And this is 2/3 now. And then here I just won a game. So I\\'ve got 2/3 and 1/3. All right. So I got all the probabilities. And now I need to figure out\\nfor the sample points what\\'s their probability. So this sample point\\nwe\\'ll call win-win. This sample point\\nis win-lose-win. This one\\'s win-lose-lose. Then we have lose-win-win,\\nlose-win-lose, and then lose-lose. So I got six sample points. And let\\'s figure out the\\nprobability for each one. Now remember the rule we\\nhad for the tree method. I just multiply these things. Well, in fact, the\\nreason we have that rule is because that is the\\nsame as the product rule. Because what I\\'m\\nasking here to compute the probability of this guy\\nis-- so the product rule gives the probability of a win-win\\nscenario-- win the first game, win the second game. By the product rule\\nis the probability that I win the first game\\ntimes the probability that I win the second game\\ngiven that I won the first game. That\\'s what the\\nproduct rule says. Probability I win the\\nfirst game is 1/2 times the probability I\\nwin the second given that I won the first is 2/3. So that equals 1/3. So what we\\'re doing\\nhere now is giving you the formal justification for\\nthat rule that we had last time and that you\\'ll always use--\\nis the probability of a sample point is the product\\nof the probabilities on the edges leading to it. It\\'s just the product rule. Now the next\\nexample is this one. And here we\\'re going to use the\\ngeneral product rule to get it. The probability of win-lose-win\\nby the general product rule is the probability that\\nyou win the first game times the probability you\\nlose the second game given the that you win the first\\ntimes the probability you win the third given what? What am I given on\\nthe product rule? Won the first, lost the second. All right. Well, now we can\\nfill in the numbers. The probability I win\\nthe first is a 1/2. The probability that\\nI lose the second given that I won the\\nfirst, that\\'s 1/3. And then this one\\nhere, the probability that I win the third\\ngiven that I won the first and lost the second,\\nthat simplifies the probability I win the third\\ngiven that I lost the second. Doesn\\'t matter what\\nhappened on the first. And that\\'s 1/3. So this is 1/2 times\\n1/3 times 1/3 is 118. And that\\'s 1/18. And it\\'s just the product\\nbecause the product rule saying product of\\nthe first probability times this one, which is\\nthe conditional probability of being here times\\nthis one, which is a conditional probability if\\nthese events happened before. Any questions about that? Very simple to\\ndo, which is good. Yeah. Is there a question? OK. All right. So let\\'s fill in the\\nother probabilities here. I got 1/2, 1/3, and 2/3. That\\'s 1/9. Same thing here is 1/9. This is 1/18 and 1/3. OK. So those are the probabilities\\nin the sample points. Now, to compute the probability\\nof winning the series given that we won the first game,\\nlet\\'s define the events here. So A be the event that\\nwe win the series. B will be the event that\\nwe win the first game. And I want to compute the\\nprobability of A given B. And we use our formula. Where\\'s the formula for that? It\\'s way back over there. The probability of A\\ngiven B is the probability of both happening, the\\nprobability of A and B divided by the probability of B. So now I just have to\\ncompute these probabilities. So to do that I got to figure\\nout which sample points are in A and B here. So let\\'s write that down. There\\'s A, B, A\\nand B. All right. So A is the event that\\nwe win the series. Now this sample point qualifies,\\nthat one does, and this one. B is the event we\\nwon the first game. And that\\'s these\\nthree sample points. And then A and B\\nintersect B is these two. All right. So for each event\\nthat I care about I figure out which sample\\npoints are in that event. And now I just add\\nthe probabilities up. So what\\'s the\\nprobability of A and B? 7/18. 1/3 plus 1/18. What\\'s the probability of B? Yeah. 1/2, 9/18. I got these three points. So this\\'ll be 1/3 third plus\\n1/18 plus the extra one, 1/9. So I\\'ve got 7/18 over 9/18. 7/9 is the answer. So the probability\\nwe win the Series given we won the\\nfirst game is 7/9. Any questions? We\\'re going to do this same\\nthing about 10 different times. OK? And it will look a little\\ndifferent each time maybe. But it\\'s the same idea. And the beauty here is\\nit\\'s really easy to do. I\\'m going to give you a\\nlot of confusing examples. But really, if you just do this\\nis it\\'s going to be very easy. All right. Somebody talked about the\\nseries lasting three games. What\\'s the probability the\\nseries lasts three games? Can anybody look at\\nthat and tell me? 1/3 because what you would do\\nis add up these three sample points. And it\\'s the opposite\\nof these two. So it\\'s 2/3 chance of two games,\\na 1/3 chance of three games. So it\\'s not likely\\nto go three games. All right. So to this point,\\nwe\\'ve seen examples of a conditional\\nprobability where it\\'s A given B where A follows\\nB, like, we\\'re told B happened. Now what\\'s the chance of\\nA. And A is coming later. The probability of\\nwinning today\\'s game given that you won yesterday\\'s\\ngame, the probability of winning the series given\\nyou already won the first game. Next, we\\'re going to look\\nat the opposite scenario where the events are\\nreversed in order. The probability that\\nyou won the first game given that you won the series. All right. Now, this is\\ninherently confusing because if you\\'re\\ntrying to figure-- if you know you\\nthe series, well, you already know what\\nhappened in the first game because it\\'s been played. So how could there be\\nany probability there? It happened. Well, so what the meaning\\nis is over all the times where the series\\nwas played, sort of what fraction of\\nthe time did the team that won the series win\\nthe first game is one way you could think about it. Or, maybe you just don\\'t know. The game was played. You know you won the series. But you don\\'t know who\\nwon the first game. And so you could think of a\\nprobability still being there. Now when you think about it,\\nit gets me confused still. But just think about\\nit like the math. It\\'s the same formula. OK. It doesn\\'t matter which\\nhappened first in time. You use the same mathematics. In fact, they give a special\\nname these kinds of things. They\\'re called a postieri\\nconditional probabilities. It\\'s a fancy name for just\\nsaying that things are out of order in time. All right? So it\\'s a probability of B given\\nA where B precedes A in time. All right? So it\\'s the same math. It\\'s just they\\'re out of order. So let\\'s figure\\nout the probability that you won the first game\\ngiven that you want the series. Let\\'s figure it out. So I want probability of B\\ngiven A now for this example. Well, it\\'s just the\\nprobability of B and A over the probability of A. We already computed the\\nprobability of A and B. That\\'s 1/3 plus 1/18. what\\'s the probability\\nof A, the probability of winning the first game? 1/2. It\\'s those three sample points\\nand they better add up to 1/2 because we sort of said, the\\nprobability of the first game\\'s 1/2. So that\\'s over\\n1/2, which is 9/18. Well this was 7/18 over 9/18. It\\'s 7/9. So the probability of\\nwinning the first game given that you won series is 7/9. Anybody notice anything\\nunusual about that answer here? It\\'s the same as the\\nanswer over there. Is that a theorem? No. The probability of A\\ngiven B is not always the probability of B given\\nA. It was in this case. It is not always true. In fact, we could\\nmake a simple example to see why that\\'s\\nnot always the case. All right. So say here\\'s your sample space. And say that this\\nis B and this is A. What\\'s the probability\\nof A given B in this case? 1. If you\\'re in B-- wait. No. It\\'s not 1. What\\'s the probability of\\nA given B If I got some-- probably less than 1. Might be I\\'ve drawn it as\\n1/3 third if it was uniform. But in this case, the\\nprobability of A given B is less than 1. What\\'s the probability\\nof B given A? 1, because if I\\'m in A I\\'m\\ndefinitely in B. All right. So that\\'s an example where\\nthey would be different. And that\\'s the generic\\ncase is they\\'re different. All right? When are they equal because\\nthey were equal in this case? What makes them equal? Let\\'s see. When does the\\nprobability of A given B equal a probability\\nof B given A? Let\\'s see. Well, If I plug-in\\nthe formula, this equals the probability of A and\\nB over the probability of B. That equals the probability of\\nB and A over a probability of A. So when are those equal? Yeah. When probability A equals\\nprobability B. All right. So that\\'s one case. What\\'s the other case? Yeah-- when it\\'s 0. Probability-- there\\'s\\nno intersection. Probability of A\\nintersect B is 0. That\\'s the other case. All right. But usually these\\nconditions won\\'t apply-- just happened to in\\nthis example by coincidence. Any questions about that? All right. Yeah. So the math is the same with\\na postieri probabilities. It\\'s really, really easy. All right. So let\\'s do another simple\\nexample that\\'ll start to maybe be a little more confusing. Say we\\'ve got two coins. One of them is a fair coin. And by that, I mean the\\nprobability comes up heads is the same as\\nthe probability comes up tails is 1/2. The other one is an unfair coin. And in this case, that\\nmeans it\\'s always heads. The probability of heads is 1. The probability of tails is 0. All right? I\\'ve got two such coins here. All right. Here is the unfair\\ncoin-- heads and heads. Actually, they make these things\\nlook like quarters sometimes. Here\\'s the fair coin--\\nheads and tails. All right. Now suppose I pick one of\\nthese at random, 50-50, I pick one of\\nthese things, and I flip it, which I\\'m doing behind\\nmy back, and lo and behold, it comes out and,\\nyou see a heads. What\\'s the probability\\nI\\'m holding the fair coin? I picked the coin,\\n50-50, behind my back. So one answer is, I picked the\\nfair coin with 50% probability. But then I flipped\\nit behind my back and I showed you the\\nresult. And you see heads. Of course, if I\\'d\\nhave shown you tails, You would have known for\\nsure it was the fair coin because that\\'s the only\\none with the tails. But you don\\'t know for sure now. You see a heads. What\\'s the probability this is\\nthe fair coin given that you saw a heads after the flip? How many people think 1/2? After all, I picked it\\nwith probability 1/2. How many people think\\nit\\'s less than 1/2? Good. OK. Somebody even said 1/3. Does that sound right? A couple people like 1/3. OK. All right. Now, part of what\\nmakes this tricky is I told you I picked the\\ncoin with 50% probability. But then I gave you information. So I\\'ve conditioned the problem. And so this is one\\nof those things you could have an\\nask Marilyn about. Is it 1/2 or is it 1/3? Because I picked\\nit with 50% chance, what does the\\ninformation do for you? Now, I\\'ll give you a clue. Bobo might have written\\nin and said it\\'s 1/2. And his proof is that\\nthree other mathematicians agreed with him. [LAUGHTER] All right? OK. So let\\'s figure it out. And really it\\'s very simple. It\\'s just drawing out\\nthe tree and computing the conditional probability. So we\\'re going to do the same\\nthing over and over again because it just works\\nfor every problem. Of course, you could imagine\\ndebating this for awhile, arguing with somebody. Is it 1/2 or 1/3? Much simpler just to do it. So the first thing is we\\nhave, which coin is picked? So it could be\\nfair-- and I told you that happens with\\nprobability 1/2-- or unfair, which is also 1/2. Then we have the flip. The fair coin is\\nequally likely to be heads or tails, each with 1/2. The unfair coin, guaranteed\\nto be heads, probability 1. All right. Now we get the sample\\npoint outcomes. It\\'s fair in heads with\\nthe probability 1/4, fair in tails,\\nprobability 1/4, unfair in heads, probability 1/2. Now we define the\\nevents of interest. A is going to be that\\nwe chose the fair coin. And B is at the\\nresult, is heads. And of course what\\nI want to know is the probability that I\\nchose the fair coin given that I saw a heads. So to do that we\\nplug in our formula. That\\'s just the\\nprobability of A and B over the probability\\nof B. And to compute that I got to figure out\\nthe probability of A and B and the probability of B. So I\\'ll make my diagram. A here, B here, A\\nand B. A is the event I chose the fair coin. That\\'s these guys. B is the event the\\nresult is heads. That\\'s this one and this one. And A intersect B,\\nThat\\'s the only point. So this is really\\neasy to compute now. What\\'s the probability\\nof A and B? 1/4. It\\'s just that sample point. What\\'s the probability of B? 3/4, 1/4 plus 1/2. So the probability\\nof A given B is 1/3. Really simple to\\nanswer this question. Just don\\'t even think about it. Just write down the tree\\nwhen you get these things. So much easier just to\\nwrite the tree down. All right. Now the key here is we\\nknew the probability of picking the fair\\ncoin in the first place. Maybe it\\'s worth\\nwriting down what happens if that\\'s a variable--\\nsum variable P. Let\\'s do that. For example, what if I hadn\\'t\\ntold you the probability that I picked the fair coin? I just picked one\\nand flipped it. Think that\\'ll change the answer? It should because you got\\nto plug something in there for the 1/2 for this to work. So let\\'s see what happens. Say I picked the fair\\ncoin with probability P and the unfair\\ncoin with 1 minus P. And this is the same\\nheads and tails, 1/2, 1/2. Heads, the probability 1. Well now, instead of 1/4\\nI get P over 2 up here. And this is now 1\\nminus P instead of 1/2. So the probability of A given\\nB is the probability of A and B is p over 2. And the probability\\nof B is P over 2 plus 1 minus P. That\\'s P over\\n2 up top, one minus P over 2, and that is all\\nmultiplied by-- what am I going to multiply-- 2 here. I\\'ll get P over 2 minus P. So the probability with which\\nI picked the coin to start with impacts the answer here. For example, what if I picked\\nthe unfair coin for sure? That would be P being 0. Well, the probability that\\nI picked the fair coin is 0 over 2, which is 0. All right though-- even\\nknow I showed you the heads, there\\'s no chance it was the\\nfair coin because I picked the unfair coin for sure. Same thing if I picked\\nthe fair coin for sure, better be the case this is 1. So I get 1 over 2 minus 1. It\\'s 1. Any questions? So it\\'s important you know\\nthe probability I picked the fair coin to start with. Otherwise, you\\ncan\\'t go anywhere. All right. What if I do the same game? Pick a coin with probability p. But now I flip it K times. Say I flip it 100 times. And every time it\\ncomes up heads. I mean you\\'re pretty sure you\\ngot the unfair coin because you never saw a tails. Right? So let\\'s do that. Let\\'s compute that scenario. So instead of a single\\nheads I get K straight heads and no tails. This would happen with\\n1 over 2 to the K. This would happen with 1\\nminus 1 over 2 to the K. So this is now p over 2 to\\nthe K. This is now P1 minus 2 to the minus K. Let\\'s recompute\\nthe probabilities. I\\'m going somewhere where this. Wait a minute. So now we\\'re\\nlooking at the event that B is K straight heads. Come up. And I want to know\\nthe probability that I picked the fair coin\\ngiven that it just never comes up tails. The math is the same. The probability now that\\nI picked the fair coin and got k straight\\nheads is just p times 2 to the minus K. The probability\\nthat I got K straight heads is P times 2 to the minus\\nK plus the chance I picked the unfair\\ncoin, which is 1 minus P. And if I multiply top\\nand bottom by 2 to the K, I get P over P plus\\nto the K 1 minus B. All right. So it gets very unlikely that\\nI\\'ve got the fair coin here as K gets big. Like if K is 100 I got\\na big number down here. And basically it\\'s\\n0 chance-- close to 0 chance of the fair coin. But now say I do the\\nfollowing experiment. I don\\'t tell you P.\\nBut I pull a coin out and 100 flips in\\na row it\\'s heads. Which coin do you think I have? I flipped it 100 straight times\\nand it\\'s heads every time. Yeah. There\\'s not enough information. You don\\'t know. What do you want to say? You want to say\\nit\\'s the unfair coin but you have no idea because I\\nmight have picked the fair coin with probability 1, in which\\ncase it is the fair coin and it just was unlucky\\nthat it came up heads 100 times in a row. But it could be. So you could say nothing if you\\ndon\\'t know the probability P. Because sure enough, if\\nI plug in P being 1 here, that wipes out the 2 to the K\\nand I just get probability 1. OK? All right. Now when this comes\\nup in practice is with things like polling. Like, we just had an election. And people do poles\\nahead of time. And they sample\\nthousands of voters from 1% of the population. And they say, OK,\\nthat 60% of the people are going to vote Republican. And they might have a margin of\\nerror, three points, whatever that means. And we\\'ll figure\\nthat out next week. What does that tell you about\\nthe electorate as a whole-- the population if they sample 1%\\nat random, 60% are Republican. Yeah? AUDIENCE: [INAUDIBLE]\\nThe options you have, is it all heads or\\nis it all tails? It should be one\\noption all heads and another option\\nat least one tails. PROFESSOR: You\\'re right. Oops. All right. At least one tail for this one. Yeah. Good. That is true. OK. Any questions\\nabout that example? OK. Now we\\'re back to the\\nelection and there\\'s a pole that says they sampled\\n1% of the population at random and 60% said they\\'re\\ngoing to vote Republican. And the margin of error\\nis 3% or something. What does that tell you about\\nthe population of the country? Nothing. That\\'s right. It is what it is. All you can conclude is\\nthat either the population is close to 60% Republican\\nor you were unlucky in the 1% you sample. That\\'s what you can conclude\\nbecause the population really is fixed in this case. It is what it is. There\\'s no randomness\\nin the population. All right? So you have next\\nweek for recitation. You\\'re going to design a\\npole and work through how to calculate the margin\\nof error and work through what that\\nreally means in terms of what the population is like. Now of course, if it comes\\nout 100 straight times heads, you\\'ve got to be really\\nunlucky to have the fair coin. And the same thing\\nwith designing the poll if you\\'re way off. Any questions about that? OK. The next example comes up\\nall the time in practice. And that\\'s with medical testing. Maybe I\\'ll leave-- no. I\\'ll take that down. We know that now. Now in this case--\\nin fact, this is a question we had on the\\nfinal exam a few years ago. And there\\'s a good chance\\nthis kind of question\\'s going to be on the\\nfinal this year. There\\'s a disease out there. And you can have a test for it. But like most medical\\ntests, they\\'re not perfect. Sometimes when it says you\\'ve\\ngot the disease you really don\\'t. And if it ways you don\\'t\\nhave it, you really do. So in this case,\\nwe\\'re going to assume that 10% of the population has\\nthe disease, whatever it is. You don\\'t get\\nsymptoms right away. So you have this test. But if you have the disease\\nthere is a 10% chance that the test is negative. And this is called\\na false negative, because the test comes back\\nnegative but it\\'s wrong, because you have the disease. And similarly, if you\\nhave the disease-- or sorry-- if you\\ndon\\'t have the disease, there\\'s a 30% chance that\\nthe test comes back positive. And it\\'s called a false positive\\nbecause it came back positive, but you don\\'t have it. So the test is pretty good. Right? It\\'s 10% false negative right,\\n30% false positive right. Now say you select a random\\nperson and they test positive. What you want to know\\nis the probability they have the disease given\\nthat it\\'s a random person. So actually, this came\\nup in my personal life. Many years ago when my wife\\nwas pregnant with Alex, she was exposed to somebody\\nwith TB here at MIT. And she took the test. And it came back positive. Now the bad thing--\\nTB\\'s a bad thing. You don\\'t want to get it. But the medicine for it\\nyou take for six months. And she was worried\\nabout taking medicine for six months when she\\'s\\npregnant because who knows what the TB medicine\\ndoes kind of thing if you have a baby. So she asked the doc, what\\'s\\nthe probability I really have the disease? The doc doesn\\'t know. The doc maybe could give\\nyou some of these steps, 10% false negative,\\n30% false positive. But it tested positive. So they just normally\\ngive you the medicine. So say this was the story. What would you say? What do you think? How many people think that\\nit\\'s a least a 70% chance you got the disease? She tested positive\\nand it\\'s only got a 30% false positive rate. Anybody? So you don\\'t think\\nshe\\'s likely to have it. How many people think\\nit\\'s better than 50-50 you have the disease? A few. How many people\\nthink less than 50%. A bunch. Yeah. You\\'re right, in fact. Let\\'s figure out the answer. It\\'s easy to do. So A is the event the\\nperson has the disease. And B is the event that\\nthe person tests positive. And of course what\\nwe want to know is the probability you\\nhave the disease given that you tested positive. And that\\'s just the probability\\nof both events divided by the probability\\nof testing positive. So let\\'s figure that\\nout by drawing the tree. So first, do you\\nhave the disease? And it\\'s yes or no. And let\\'s see. The probability of\\nhaving the disease, what is that for a random person? 10%. that the stat. So it\\'s-- actually,\\nwe\\'ll call it 0.1. And 9.9 you don\\'t have it. And then there\\'s the test. Well, you can be\\npositive or negative. Now if you have\\nthe disease, there is a-- the chance you\\ntest negative is 10%, 0.1. Therefore there\\'s a 90%\\nchance you test positive. Now if, you don\\'t\\nhave the disease, you could test either way. If you don\\'t have the\\ndisease there\\'s a 30% chance you test positive. 30 here and 70% percent\\nchance you\\'re negative. Now we can compute each\\nsample point probability. This one is 0.1\\ntimes 0.9 is 0.09. 0.1 times 1 is 0.01. 0.9 and 0.3 is 0.27. 0.9 and 0.7 is 0.63. So all sample points\\nare figured out. Now we figure out which sample\\npoints are in which sets. So we have event A, event B,\\nand A intersect B. Let\\'s see. A is the event you\\nhave the disease. That\\'s these guys. B is the event\\nyou test positive. That\\'s this one and this one. A intersect B is just this one. All right. We\\'re almost done. Let\\'s just figure\\nout the probability you have the disease. What\\'s the probability\\nof A intersect B? 0.09. It\\'s just that one sample point. What\\'s the probability\\nthat you tested positive? 0.36. Yeah. 0.09 plus 0.27, which is 0.36. So I got 0.09 over 0.36 is 1/4. Wow. That seems bizarre. Right? You\\'ve got a test, 10%\\npercent false negative, 30% false positive. Yet, when you test positive\\nthere\\'s only a 25% chance you have the disease. So maybe you don\\'t\\ntake the medicine. So if there\\'s risk\\nboth ways, probably don\\'t have the disease. Yeah? AUDIENCE: [INAUDIBLE]\\ndisease change because you\\'ve\\nalready been exposed to somebody that has it? PROFESSOR: That\\'s a\\ngreat point, great point, because there\\'s\\nadditional information conditioning this in the\\npersonal example I cited. You were exposed to somebody. So we need to condition\\non that as well, which raises the chance\\nyou have the disease. That\\'s a great point. Yeah. Just like in the-- well, we\\nhaven\\'t got to that example. Do another example with\\nthat exact kind of thing is very important. All right. So this is sort of\\nparadoxical that it looks like a pretty good\\ntest-- low false positive, full false negatives, but\\nlikely be wrong, at least if it tells you have the disease. In fact, let\\'s figure out. What\\'s the probability\\nthat the test is correct? What\\'s the probability the\\ntest is right in general? 72%. Let\\'s see. So it would be 0.09 plus 0.63. 72%. So it\\'s likely to be right. But if it tells you\\nyou have the disease it\\'s likely to be wrong. It\\'s hard. Why is this happening? Why does it come out that way? Yeah? AUDIENCE: Then there is\\nonly a 1 in 64 chance that you have the disease. So if it comes back\\nnegative, then it\\'s a pretty good indication\\nthat you\\'re OK. PROFESSOR: Yeah. If it comes back negative than\\nit really is doing very well. That\\'s right. But why is it when it\\ncomes back positive that you\\'re unlikely to have\\nthe disease if it\\'s a good test. Yeah. AUDIENCE: The\\ndisease is so rare. PROFESSOR: The\\ndisease is so rare. Absolutely. This number here is so small. And that\\'s what\\'s doing it. Because if you look at how\\nmany people have the disease and test positive, it\\'s 0.09. So many people don\\'t\\nhave the disease that even with a small false\\npositive rate, this number swamps out that number. In fact, imagine\\nnobody had the disease. You\\'d have a 0 here. All right? And then you would always be\\nwrong if you said you had it. OK? That\\'s good. OK. This comes up in weather\\nprediction, the same paradox. For example, say you\\'re\\ntrying to predict the weather for Seattle. Sometimes it seems\\nlike this in Boston. And you just say,\\nit\\'s going to rain. Forget all the fancy weather\\nforecasting stuff, the radar, and all the rest. Just say it\\'s going\\nto rain tomorrow. You\\'re going to be right\\nalmost all the time. All right? And in fact, if you\\ntry to do fancy stuff, you\\'re probably going to\\nbe wrong more of the time. All right. For example, in this\\ncase, if you just say the person does not have the\\ndisease, forget the lab test. Just come back with negative. How often are you right? 90% of the time you\\'re right. Much better than the test\\nyou paid a lot of money for. I see. You\\'ve got to be careful\\nwhat you\\'re looking for, how you measure the value\\nof a test or a prediction. Because presumably\\nthe one you paid for is better, even though\\naccurate less of the time. Any questions about that? OK. So For the rest of\\ntoday we\\'re going to do three more paradoxes. And in each case\\nthey\\'re going to expose a flaw in our intuition\\nabout probability. But the good news\\nis in each case it\\'s easy to get the right answer. Just stick with the math and\\ntry not to think about it. Now the first example\\nis a game involving dice that\\'s called carnival dice\\nthat you can find in carnivals and you can also\\nfind in casinos. It\\'s a pretty popular\\ngame, actually. So the way it works\\nis as follows. The player picks a number from\\n1 to 6-- we\\'ll call it N-- and then rolls three dice. And let\\'s say they\\'re fair\\nand mutually independent. We haven\\'t talked\\nabout independent. So they\\'re fair dice. For now, normal\\ndice-- nothing fishy. And the player wins if and\\nonly if the number he picked comes up on at least\\none of the dice. So you either win\\nor you lose the game depending on if your lucky\\nnumber came up at least once. Now you\\'ve got three dice,\\neach of which has a 1 in 6 chance of coming\\nup a winner for you. So how many people think\\nthis is a fair game-- you got a 50-50 chance of\\nwinning-- three dice, each 1/6 chance of winning? Anybody think it\\'s\\nnot a fair game? A bunch of you. How many people think it\\nis a fair game-- 50-50? A few. All right. Well, let\\'s figure it out. And instead of doing\\nthe tree method, which we know we\\'re\\nsupposed to do, we\\'re just going to wing it, which\\nis always seems easier to do. If you\\'re in the Casino\\nyou want to just wing it instead of taking your napkin\\nout and drawing a tree. So the claim, question mark, is\\nthe probability you win in 1/2. And the proof, question\\nmark, is you let Ai be the event that the i-th die\\ncomes up N. And i is 1 to 3 here. So then you say, OK. The probability I win is\\nthe probability of A1-- I could win that\\nway-- or A2, or A3. All I need is one of the\\ndie to come up my way. And that is the\\nprobability of A1 plus the probability of A2\\nplus the probability of A3. And each die wins for\\nme with probability 1/6. And that is then 1/2. So that\\'s a proof that we\\nwin with probability of 1/2. What do you think? Any problems with that proof? AUDIENCE: [INAUDIBLE] PROFESSOR: Well\\nthat\\'s a great point. Yeah. So if I extended this\\nnice proof technique I couldn\\'t have probability of\\n7/6 of winning with seven die. Yeah? AUDIENCE: [INAUDIBLE] PROFESSOR: Yeah. You\\'re very close. I didn\\'t technically\\nassume that. AUDIENCE: [INAUDIBLE] PROFESSOR: They could double up. Yeah. There\\'s no intersection\\nin the events. In fact, there is\\nintersection because there\\'s a chance I rolled\\nall six-- all Ns. Say N is 6. I could roll all sixes\\nand then each of these would be a winner. But I don\\'t get to\\ncount them separately. Then I only win\\nonce in that case. In other words, all of\\nthese could turned on at the same time. There\\'s an intersection here. So this rule does not hold. I need the Ai to be\\ndisjoined for this to be true-- the\\nevents to be disjoined. And they\\'re not\\ndisjoined because there\\'s a sample point were\\ntwo or more of the die could come up the same\\nbeing a winner, which means the same sample\\npoint, namely all die are N, comes up in each of these three. So they\\'re not disjoined. Now what\\'s the principal\\nyou used two weeks ago when you did cardinality of a set--\\ncardinality of a union of sets? Inclusion, exclusion. And the same thing\\nneeds to be done here. So let\\'s do that. And then we\\'ll figure out\\nthe actual probability. So this is a fact based on the\\ninclusion, exclusion principle. The probability of A1,\\nunion A2, union A3, is just what you think it would\\nbe from inclusion, exclusion. It\\'s a probability of\\nA1 plus a probability of A2 plus the\\nprobability of A3 minus the pairwise intersections. A1 intersect A3 minus\\nprobability of A2 intersect A3. And is there anything else? Plus, the probably of\\nall of them matching. OK. So the proof is\\nreally the same proof you use for inclusion,\\nexclusion with sets. The only difference is that\\nin a probability space, we have weights on the elements. And the weight corresponds\\nto the probability. So in fact, if you were drawing\\nthe sample space, say here\\'s A1 and here\\'s A2, and here\\'s A3. Well, you need to add the\\nprobabilities here, here, and here. Then you subtract off the double\\ncounting from here, from here, and from here. And then you add back again\\nwhat you subtracted off too much there. Same proof, it\\'s just your\\nhave weights on the elements of probabilities. All right. So let\\'s figure out\\nthe right probability. That\\'s 1/6, 1/6, 1/6. What\\'s the probability\\nof the first two die matching-- both of them? 1/36. We\\'ll talk more about\\nwhy that is next time. But there\\'s a 6 for A1 then\\ngiven that 1/6 for the second die matching. So it\\'s 1/6 times\\n1/6 minus the 1/36. 1/36, the chance that all three\\nmatch is 1/216 or 6 cubed. So when you add all that up you\\nget the 0.421 and some more. So the chance of\\nwinning this game is 41% which makes it a\\nworst game in the casino. It is hard to find a\\nworse game than this. Roulette, much better. We\\'ll study Roulette in the\\nlast lecture-- much better game. And even that\\'s a\\nterrible game to play. So it looks like an easy game. There\\'s a quick proof\\nthat it\\'s 50-50. But it\\'s horrible odds\\nagainst the house. Now, this is a nice\\nexample because it shows how a rule you had for\\ncomputing the cardinality of a set gives you\\nthe probability. All right. In fact, all the set laws you\\nlearned a couple weeks ago work for probability\\nspaces the same way. And there were several\\nof those in homework that you just had\\nthe last problem set. Any questions about that? OK. Now in addition, all those\\nset laws you did also work for conditional\\nprobabilities. For example, this is true. The probability of A union B\\ngiven C-- whoops-- given C, is the probability of A given\\nC plus the probability of B given C minus the intersection,\\nA intersect B given C. In other words, take any\\nprobability rule you have and condition everything on an\\nevent, C, and it still works. And the proof is not hard. You can go through\\neach individual law but it all comes out to be fine. All right. You have to be a little\\ncareful though because you got to remember which\\nside you\\'re doing, which what you\\'re putting on\\neither side of the bar here. For example, what\\nabout this one? Is this true? Claim. Let\\'s take-- say C\\nand D are disjoined. Is this true? Then the probability\\nof A conditioned on C union D. So given\\nthat either C or D is true, does that equal the\\nprobability of A given C plus probability of A given D? We know that if I swapped\\nall these, it\\'s true. The probability of C union\\nD when C and D are disjoined is the probability that C given\\nA plus the probability of D given A. That I just claimed. And what about this way? Can I swap things around? Yeah? AUDIENCE: [INAUDIBLE]\\nwould C union D be 0? PROFESSOR: If C and\\nD are disjoined, C union D would just be C union\\nD. But you\\'re not a good point. What if C and D are disjoined? That\\'s a good example. Let\\'s draw that. Let\\'s look at that case. So we\\'ve got a\\nsample space here. And you\\'ve got C\\nhere and D here. And just for fun, let\\'s make A\\nbe here-- include all of them. What\\'s the probability-- is\\nthis going to do what I want? Yeah. What\\'s the probability\\nof A given C? 1. If I\\'m in C I\\'m in A.\\nA is everything here. So the probability\\nof A given C is one. What\\'s the probability\\nof A given D? 1. All right. Well, this is a\\nproblem because I can\\'t have the probability ot--\\nwhat\\'s the probably of A given C union D? Well, it can\\'t be 2. Right? It\\'s 1. They are not equal. So you cannot do those set\\nrules on the right side of the conditioning bar. You can do them on the\\nleft, not on the right. All right. So this is not true. Now nobody would do this. Right? I mean, the probability of-- not\\nthat it\\'s-- see this example? This you just would never\\nmake this mistake again seeing that example. Everybody understand\\nthe example, how it\\'s clearly\\nnot always the case that probability\\nof A given C union D is a probability of A given C\\nplus probability of A given D? Because now I\\'m going to show\\nyou an example where you\\'re going to swear it\\'s true. All right? And this is a real life example. Many years ago now there was\\na sex discrimination suit at Berkeley. There was a female professor\\nin the math department. And she was denied tenure. And she filed a lawsuit\\nagainst Berkeley alleging sex discrimination. Said she wasn\\'t tenured\\nbecause she\\'s a woman. Now, unfortunately\\nsex discrimination is a problem in\\nmath departments. It\\'s historically\\nbeen a difficult area. But it\\'s always hard to prove. It\\'s a nebulous kind of thing. They don\\'t say, hey,\\nyou can\\'t have tenure because you\\'re a woman. They\\'d get sued and\\nget killed for that. So she had to get some\\nmat to back her up. So what she did is she looked\\ninto Berkeley\\'s practices and she found that in\\nall 22 departments, every single department,\\nthe percentage of male PhD applicants\\nthat were accepted was higher than the percentage\\nof female PhD applicants that were accepted. Now you could understand some of\\nthe departments accepting more male PhDs than female PhDs. But all 22? What are the odds of that? I mean, so the\\nimmediate conclusion is, well, that\\'s clearly there\\'s\\nsex discrimination going on at Berkeley. OK? Well Berkeley took a look at\\nthat and said, nothing good. That doesn\\'t look good for them. But they did their own\\nstudy of PhD applicants. And they said that if the\\nuniversity as a whole-- look at the University as a\\nwhole, actually, the women, the females have a higher\\nacceptance rate for the PhD Program than the men. So look. Berkeley said, we\\'re\\naccepting more women than men percentage-wise. So how could we be\\ndiscriminating against women? And this is where the same\\nargument the female faculty member\\'s making, But they\\'re\\nsaying as a university as a whole, when you add\\nup all 22 departments. Well, that sounds pretty good. How could they be\\ndiscriminating? OK. So the question for you\\nguys, is it possible that both sides we\\'re\\ntelling the truth, that in every single department\\nthe women have a lower acceptance rate than men, but\\non the university as a whole the women are higher percentage? It sounds like it\\'s-- and just\\nto avoid any confusion here, people only apply to one\\ndepartment and they\\'re only one sex. So you can\\'t--\\nCarroll didn\\'t apply. [LAUGHTER] How many people think that one\\nof the sides, actually, when they look at the\\nstudies was wrong, that they\\'re contradictory? Nobody? You\\'ve been in 6\\nover 2 too long. How many people\\nthink it\\'s possible that both sides were right? Yeah. All right. So let\\'s see how this works. And to make it simple\\nI\\'m going to get down to just two departments rather\\nthan try to do data for all 22. And I\\'m going to do not the\\nactual data but something that\\'s represents\\nwhat\\'s going on. OK. So we\\'re going to look\\nat the following events. A is the event that the\\napplicant is admitted. FCS is the event\\nthat the applicant is female and applying to CS. FEE is the event\\nthat the applicant is female and applying to EE. MCS is the event the\\napplicant is a male and CS. And then finally we have MEE\\nis the event the applicant is male and in EE. So we\\'re just going to\\nlook at two departments here and try to figure\\nout if it can happen that in both departments\\nthe women are worse off but if you take the\\nunion they\\'re better off. So the female professor\\'s\\nargument effectively is, the probability of being\\nadmitted given that you\\'re a female in CS is less than the\\nprobability of being admitted given that you\\'re a male at CS. And same thing in EE. Probability of being admitted\\nin EE if you\\'re a female is less than if you\\'re a male. OK? Now Berkeley is saying\\nit\\'s sort of the reverse. The probability\\nthat you\\'re admitted given that you\\'re a female\\nin either department is bigger than the probability\\nof being admitted if you\\'re a male in either department. OK. So we\\'ve now expressed\\ntheir arguments as conditional\\nprobabilities Any questions? Can you sort of see why\\nthis seems contradictory? Not plus, union. Because this is sort of\\nlike-- these are just joined. This is the sum of those. And this is sort of\\nthe sum of those. And yet the inequality changed. All right. In fact, this is the logic\\nthat we\\'ve just debunked over there-- exactly that claim. In fact, these are\\nnot equal as the sum. So let\\'s do an example. Say that-- let\\'s\\ndo it over here. I\\'ll put the real\\nvalues in over here. Say that for women in\\ncomputer science, 0 out of 1 were admitted compared to\\nthe men, were 50 out of 100 were admitted. And then in EE, 70\\nout of 100 women were admitted compared to the\\nmen, which had 1 out of 1. All right? So as ratios, 70%\\nis less than 100%. 0% is less than 50. Now if I look at the two\\ndepartments is a whole, I get 70 over 101 is in fact\\nbigger than 51 over 101. All right? And so as a whole\\nwomen are a lot more likely to be admitted even\\nthough in each department they\\'re less likely\\nto be admitted. OK? So what went wrong with\\nthe intuition, which you didn\\'t fall victim\\nto, but people often do, that it shouldn\\'t have\\nbeen possible given that? What\\'s going on\\nhere that make it so that it\\'s not\\na less than when you look at the union\\nof the departments? Yeah? AUDIENCE: [INAUDIBLE]\\nthey\\'re weighted differently? PROFESSOR: Yeah. They\\'re weighted\\nvery differently. You got huge waves here. Right? So if I look at the average\\nof the percentages here, well it\\'s 35% for the women\\nversus 75% for the men. So the average of the percentage\\nis just what you\\'d think. 35 is less than 75. But I\\'ve got huge weightings\\non these guys, which changes the numbers quite dramatically. So it all depends\\nhow you count it. Actually, who do you\\nthink had a better-- Yeah. Go ahead. AUDIENCE: [INAUDIBLE] PROFESSOR: Who won the lawsuit? Actually, the woman\\nwon the lawsuit. And which argument\\nwould you buy now? You\\'ve got two arguments. Which one would you\\nbelieve if either? Which one? I mean, now if I look\\nat exactly this data I might side-- I might\\nside with Berkeley looking at these numbers. Then again, when you think about\\nall 22 departments and the fact they weren\\'t this\\nlopsided, not so good. So in the end Berkeley lost. I\\'m going to see another\\nexample in a minute where it\\'s even more clear\\nwhich side to believe in. But it really depends\\non the numbers as to which one you\\nmight, if you had to vote, which way you\\'d vote. Here\\'s another example. This is from a newspaper article\\non which airlines are best to fly because they have\\nthe best on-time rates. And in this case they were\\ncomparing American Airlines and America West,\\nlooking at on-time rates. And here\\'s the data they\\nshowed for the two airlines. Here\\'s American Airlines. Here\\'s America West. And they took five cities,\\nLA, Phoenix, San Diego, San Francisco, and Seattle. And then you looked\\nat the number on time, the number of flights, and then\\nthe rate, percentage on time. And then same thing here. Number on time, number\\nof flights, and the rate. So I\\'m just going to give\\nyou the numbers here. So they had 500 out of 560 for\\na rate of 89%, 220 over 230 for 95, 210 over 230 for\\n92%, 500 over 600 for 83%, and then Seattle. They had a lot of flights. That\\'s where they\\'re-- we\\nhave a hub of 2,200 for 86%. And if you added them all up,\\nthey got 3,300 out of 3,820 for 87% on time. Now the data for\\nAmerican West looks something like the following. In LA it\\'s 700 out\\nof 800 for 87%. they\\'re based in Phoenix. They got a zillion\\nflights there. 4,900 out of 5,300 for 92%. And 400 over 450 for 89%, 320,\\nover 450, 71%, 200 over 260 for 77%. And then you add all them up. And you\\'ve got 6,520\\nover 7,260 for 90%. So the newspaper concluded\\nand literally said that American West\\nis the better airline to fly because they\\'re\\non-time rate is much better. It\\'s 90% versus 87%. What do you think? Which airline would you\\nfly looking at that data? AUDIENCE: [INAUDIBLE] PROFESSOR: I know\\nwhich one I\\'d fly. It looks like America\\nWest is better. Every single city, American\\nAirlines is better. 92 versus 89. Everywhere it\\'s\\nbetter by a bunch. 83 versus 71. 86 versus 77. Every single city, American\\nAirlines is better. Yet, America West\\nis better overall. And that\\'s what\\nthe newspaper said. They went on this. But of course, no matter\\nwhere you\\'re going you\\'re better off with\\nAmerican Airlines. All right? Now what happened here? The waiting. In fact, America West\\nflies out of Phoenix where the weather\\'s great. So you get a higher on-time rate\\nwhen in a good-weather city. And they got most of\\ntheir flights there. American Airlines got a\\nlot of flights in Seattle where the weather sucks\\nand you\\'re always delayed. All right? And so they look\\nworse on average because so many of their\\nflights are in a bad city and so many of America\\nWest are in a good city. All right? So it makes America\\nWest look better when in fact, in this case, it\\'s\\nabsolutely clear whose better. American Airlines is\\nbetter, every single city. All right. That\\'s why Mark\\nTwain said, \"There\\'s three kinds of lies-- lies,\\ndamned lies, and statistics.\" We\\'ll see more\\nexamples next time.'], Target: 1\n",
            "Features: [b'The following content is\\nprovided under a Creative Commons license. Your support will help MIT\\nOpenCourseWare continue to offer high-quality educational\\nresources for free. To make a donation or view\\nadditional materials from hundreds of MIT courses, visit\\nMIT OpenCourseWare at ocw.mit.edu. SHAN-YUAN HO: OK. So today\\'s lecture\\nis going to be on Finite-state Markov Chains. And we\\'re going to use\\nthe matrix approach. So in last lecture, we saw\\nthat the Markov chain, we could represent it as a directed\\ngraph or as a matrix. So the outline is we will look\\nat this transition matrix and its powers. And then we\\'ll want to know\\nwhether this p of n is going to converge for very,\\nvery large n. Then we will extend this to\\nErgodic Markov chains, Ergodic unichains, and other\\nfinite-state Markov chains. So remember in the Markovity,\\nthese Markov chains, the effect of the past on the future\\nis totally summarized by its state. So we want to analyze the\\nprobabilities of properties of the sequence of these states. So whatever the state you are\\nin, all the past is totally summarized in that state. And that\\'s the only thing\\nthat affects the future. So an ergodic Markov chain is\\na Markov chain that has a single recurrent class\\nand is aperiodic. So this chain doesn\\'t contain\\nany transient states. And it doesn\\'t contain\\nany periodicity. So an ergodic unichain is just\\nergodic Markov chain, but it has some transient\\nstates in it. So the state x sub n of this\\nMarkov chain at step n depends only on the past through\\nthe previous step. So for n steps, we want\\nto be at state j. And then we have this path. x sub n minus 1 is i, and\\nso forth, up to x0. It\\'s just the probability\\nfrom i to j, from state i to state j. So this means that we can write\\nthe joint probability of all these states that we\\'re in,\\nso x0, x1, all the way up to xn, as a function of these\\ntransition probabilities. So in this transition\\nprobability matrix, we can represent these transition\\nprobabilities. We see that here, in this\\nexample, this is a 6-state Markov chain. So if I want to go from, say,\\nstate 2 to state 1 in one step, it would just\\nbe p of 2,1. If I want to go from\\nstate 6 to itself-- this is last one, which\\nis p of 6,6. So this is a probably\\ntransition matrix. So if we condition on the state\\nat time 0 and then we define this p of ijn is equal to\\nthe probability that we\\'re in state j at the n-th step,\\ngiven that we start x0 is equal to i, let\\'s look at what\\nhappens when n is equal to 2. So in a 2-step transition,\\nwe go from i to j. It\\'s just the probability that\\nat step 2, x2 is equal to j, x1 is equal to some k,\\nand x0 is equal to i. So remember, we started\\nin state i. But this has to be multiplied\\nby probability that x1 is equal to k, given that\\nx0 is equal to i. And we have to sum this over all\\nthe states k, in order to get the total probability\\nfrom-- Oh, stand back? OK. There. OK. So this is just probability\\nof ij in two steps. It\\'s just the probability of\\ni going to k times the probability of k going to j,\\nsummed over all k states. So we notice that this term\\nright here, the sum over k or ik, kj is just the ij term of\\nthe product of the transition matrix P with itself. So we represent this\\nas P squared. So we multiply the transition\\nmatrix by itself. This gives us the 2-step\\ntransition matrix of this Markov chain. So if you want to go i to j, you\\njust look at ij element in this matrix. And that gives you the\\nprobability in two steps, going from state i to state j. So for n, we just iterate\\non this for successively larger n. So for n state to get from state\\ni to state j, we just have this probability x sub n,\\ngiven j, given x of n minus the previous step is equal to\\nk, x sub n minus 1 equals k, given x0 is equal to i,\\nsumming over all k. So this means that we broke\\nthis up for n-th step. In the n minus one step,\\nwe visited state k. And then we multiplied that\\none-step transition from k to j because we want to arrive\\nat j starting at i. But again, we have to sum over\\nall the k\\'s in order to get the probability from\\ni to j in n steps. So p of n right here, this\\nrepresentation is just the transition matrix multiplied\\nby itself n times. And this gives you the n-th step\\ntransition probabilities of this Markov chain. So computationally, what you do\\nis you take p, p squared, p to the fourth. If you wanted p to the 9th,\\nyou\\'d just take p eighth multiplied by p, to to\\nmultiply by this. So this gives us this thing\\ncalled the Chapman-Kolmogorov equations, which means that when\\nwe want to go from step i to step j, we can go to an\\nintermediate state and then sum up all the states that\\nwould go into the intermediate state. So in this case, if the step is\\nm plus n transition, we can break it up into m and n. So it\\'s the probability that it\\ngoes from i to k in exactly m steps and k to j in n steps,\\nsumming over all the k\\'s that it visits on its way\\nfrom i to j. So this is very useful a\\nquantity that we can manipulate our transition\\nprobabilities when we get higher orders of n. So the convergence\\nof p to the n. So a very important question we\\nlike to ask is as n goes to infinity whether this goes\\nto a limit or not. In other words, does the initial\\nstate matter, all initial sates matter in\\nthis Markov chain? So the Markov chain is going\\nto go on for a long, long, long, long, long time. And at the n-th state where n is\\nvery large, is it going to depend on i? Or is it going to depend on n,\\nwhich is the number of steps? If it goes to this quantity,\\nsome limit, then it won\\'t depend on this. So let\\'s assume that\\nthis limit exists. If this limit does exist, we can\\ntake the sum of this limit and then multiply it by p of\\njk, summing over all j. So we do a sum of over j. So we\\'re going from j to\\nk on both sides, and we sum over all j. So we take this limit\\nright here. We notice that this left side\\ngoing from i to k to n plus 1 is just that this limit\\nat state k exists. Because we saw assumed up here\\nthat this exists for all i and all j. So therefore, if we take the n\\nplus 1 step, we take this n going to infinity of i to k,\\nit has to go to pi of k. So when we do this,\\nwe could simplify this equation up here. And if it doesn\\'t exist, we have\\nthis pi sub k for all the states in the Markov chain. So this is just a vector. So pi sub k is equal to pi sub j\\ntimes the probability from k to j, summed over all j. So if you have an m state Markov\\nchain, you have exactly m of these equations. And this one, we\\'ll call it the\\nvector pi, which consists of each element of this\\nequation, if the limit is going to exist. But we don\\'t know whether\\nit does or not, at this point in time. So if it does exist, what\\'s\\ngoing to happen? So that means I\\'m going to\\nmultiply this probability matrix, P times P,P P, P,\\nP, P, P all the way. And if the limit exists, then\\nthat means for each row, they must be all identical. Because we said the limit\\nexists, then going from 1 to j, 2 to j, 3 to j, 4 to\\nj, they should be all exactly the same. This is also the equivalent of\\nsaying, when I look at this large limit, as n is very,\\nvery large if the limit exists, that all the elements\\nin the column should be exactly the same as well,\\nor all the rows. So the elements are equal to\\neach other, or all the rows, if I look at the row, which is\\ngoing to be this pi vector. They should be the same. So we define this vector. If this limit exists, the\\nprobability vector is this vector pi. Because we said it was an\\nm state Markov chain. Each pi sub i is non-negative,\\nand they obviously have to sum up to 1. So this is what we call a\\nprobability vector, called the steady-state vector,\\nfor this transition matrix P, if it exists. So what happens is this limit\\nis easy to study. In the future in the course, we\\nwill study these pi P, this steady-state vector for\\nvarious Markov chains. And so you see, it is quite\\ninteresting, many things that could come about it. So we notice that this\\nsolution can contain more than one. It may not be unique. So if it contains more than one,\\nit\\'s very possible that it has more than one solution,\\nmore than one probability vector solution. But just because a solution\\nexists to that, it doesn\\'t mean that this limit exists. So we have prove that\\nlimit exists, first. So for ergodic Markov chain,\\nhere we have another way to express this that this matrix\\nconverges is that the matrix of the rows-- the elements in the column are\\nall the same for each i. So we have this theorem. And today\\'s lecture is going to\\nbe completely this theorem. This theorem says that if you\\nhave an ergodic finite-state Markov chain-- so when we say\\n\"ergodic,\" remember it means that there\\'s only one class,\\nevery single state in this is recurrent, you have no transient\\nstates, and you have no periodicity. So it\\'s an aperiodic chain. And then for each j, if you take\\nthe maximum path from i to j in n steps, this is\\nnon-increasing in n. So in other words, this right\\nhere, this is non-increasing. So if I take the maximum path\\nfrom state i to j, it gives you exactly n steps. So that means this is\\nmaximized over all initial states i. So it doesn\\'t matter what state\\nyou start, and I take the maximum path. And if I increase n, and I take\\nmaximum of that again, the maximum path, this\\nis not increasing. And the minimum is\\nnon-decreasing in n. So as we take n, the path from\\ni to j, this n getting larger and larger, we have that the\\nmaximum of this path, which is the most probable path,\\nis non-increasing. And then the minimum of this\\npath, the least likely path, is going to be non-decreasing. So we\\'re wondering whether\\nthis limit is going to converge or not. In this theorem it said that\\nfor an ergodic finite-state Markov chain, this limit\\nactually does converge. So in other words, the lim sup\\nis equal to lim if of this and will equal pi sub j, which is\\nthe steady-state distribution. And not only that, this\\nconvergence is going to be exponential in n. So this is the theorem that\\nwe will prove today. So the key to this theorem is\\nthis pair statements, that the most probable path from i\\nto j, given n steps-- so this is the most\\nprobable path-- is non-increasing at n,\\nand the minimum is non-decreasing in n. So the proof is almost trivial,\\nbut let\\'s see what happens in this. So we have a probably\\ntransition matrix. So this is the statement\\nright here. And the transition is just one\\nhere and one here, with probability 1, 1. In this case, we want to say,\\nwhat is the maximum path that we\\'re in state 2,\\ngiven n steps? So we know that this probability\\nalternates between 1 and 2, it\\'s non-increasing,\\nit\\'s not decreasing, it\\'s always the same. So those two bounds are\\nmet with equality. So in this here. So the second example is this. We have a two-state\\nchain again. But this time, from 1 to 2, we\\nhave the transition of 3/4. So that means that we have\\na chain here of 1/4. See, the minute we put a\\nself-loop in here, it completely destroys\\nthe periodicity. Any Markov chain, you put a\\nself-loop in it, and the periodicity is destroyed. So here we have 3/4. So this has to come\\nback with 1/4. All right. So in this one, let\\'s look at\\nthe n step going from 1 to 2. So basically, we want\\nto end up in state 2 in exactly n steps. So when n is equal to 1,\\nwhat is the maximum? The maximum is if you start it\\nin this state and then you went to state 2. The other alternative is you\\nstart at state 2, and you stay in state 2. Because we want to end at state\\n2 in exactly one step. So the maximum is going to\\nbe 3/4, and the minimum is going to be 1/4. You get n is equal to 2. Now we want to end up in\\nstate 2 in two steps. So what is going to\\nbe the maximum? The maximum is going\\nto be if you visit state 1 and then back. So n is equal to 1. Then P1 from 1 to 2\\nis equal to 3/4. So the probability from 1 to 2\\nin two steps is equal to 3/8. So it goes 1/4 plus\\n3/4, 3/4 plus 1/4. It should be equal\\nto 3/8, right? Is that right? OK. And then it when P1,2 to 3, if\\nthere are three transitions from 1 to 2, then it\\'s\\nequal to 9/16. So if for 2, if I want\\nto transition from 2 to 2 n steps-- so P2,2 is equal to 1/4. So it just stayed by itself. So P2,2 in two steps, you\\ndon\\'t have a choice. You have to go from\\n3/4 to 3/4. So that\\'s 9/16. But For thing is I can also stay\\nhere by 1/4 times 1/4. So that gives me 5/8\\nand so forth. So basically, the sequence going\\nfrom 1 to 2 is going to be oscillating between 3/4,\\n3/8, 9/16, and so forth. And then going from 2,2, it\\'s\\ngoing to be oscillating too. We can see that\\'s\\n1/4, 5/8, 7/16. So what happens is this\\noscillation is going to converge-- it\\'s going to\\napproach, actually, 1/2. So if we take the maximum of\\nthese two, so P1,2 and P2,2-- because that means that we\\'re\\ngoing to end at state 2. And maximum over n steps, then\\nwe just look at these two numbers, the 3/4 and 1/4, if we\\nwant the maximum, then it\\'s going to be 3/4. For the 3/8 and 5/8, the maximum\\nis going to be 5/8, the 9/16 and 7/16, the 9/16\\nwill be the maximum. And similarly, we compare it,\\nand we take the minimum. And the minimum is 1/4,\\n3/8, and 7/16. So we see that the maximum\\nis going to be-- it starts high. And then it\\'s going to\\ndecrease toward 1/2. And the minimum, what happens\\nis it\\'s going to start low, and then it\\'s going to\\nincrease to 1/2. So this is exactly\\nthis one here. So P\\'s transition makes this\\nan arbitrary finite-state Markov chain. Therefore, each j, this maximum\\npath, the most problem path from i to j in n steps\\nis non-increasing n. And the minimum is\\nnon-decreasing n. So you take n plus 1\\nsteps from i to j. So we\\'re going to use that\\nChapman-Kolmogorov equation. So we take the first step\\nto some state k. And then we go from\\nk to j in n steps. But then we sum this\\nover all k. But this P n for state to j to\\nk in n steps, I can just take the maximum path. So I take the most probable\\npath, the state that gives me the most probable path, and\\nI substitute this in. When I substitute this in,\\nobviously every one of these guys is going to be less\\nthan or equal to this. Therefore, this outside\\nterm is going to be less than or equal. So now this is just going\\nto be a constant. So I sum over all k, and\\nthen this term remains. So therefore, what we know is\\nif I want to end up in state j, and for n steps, if I\\nincrease the step more, to n plus 1, we know that this\\nprobability is going to stay the same or decrease. It\\'s not going to increase. So you could do exactly the same\\nthing for the minimum. So if this is going to be true,\\nthen of course, if I think the maximum of this,\\nit\\'s also going to be less than that. Because this limit\\'s true\\nfor Markov chain. It doesn\\'t matter. It just has to be a finite-state\\nMarkov chain. So this is true for any\\nfinite-state Markov chain. So if I take the maximum of\\nthis, it\\'s less than or equal to the maximum of\\nthe n-th step. So n plus 1 steps, the path is\\ngoing to be less probable when I take the maximum path, the\\nfact that I end up at state j than n. So before we complete the proof\\nof this theorem, let\\'s look at this case where P\\nis greater than zero. So if we say Pis greater than\\nzero, this means that every entry in this matrix is greater\\nthan 0 for all i, j, which means that this graph\\nis fully connected. So that means you could get from\\ni to j in one step with nonzero probability. So if P is greater than 0-- and let this be the\\ntransition matrix. So we\\'ll prove this first, and\\nthen we\\'ll extend it to the arbitrary finite Markov chain. So let alpha here is equal\\nto the minimum. So it\\'s going to be the minimum\\nelement in this transition matrix. That means it\\'s going to be the\\nstate that contains the minimum transition. So let\\'s call alpha-- it\\'s\\nthe minimum probability. Excuse me. So let all these\\nstates i and j. And for n greater than or equal\\nto 1, we have these three expressions. So this first expression says\\nthis, that if I have an n plus 1 walk from i to j, I take\\nthe most probable of this walk over i. So my choices, I can choose\\nmy initial starting state. In n plus 1 steps, I want\\nto end in state j. So I pick the most\\nprobable path. If I minus this, which is the\\nleast probable path-- but you get to minimize this\\nover i, over the initial starting a state. So this is less than or\\nequal to the n step. It\\'s exactly this term\\nhere, the n step times 1 minus 2 alpha. So alpha is the minimum\\ntransition probability in this probability transition matrix. So this one, it\\'s not so\\nobvious right now. But we are going to prove\\nthat in the next slide. So once we have this, we can\\niterative on n to get the second term. So for this term inside here,\\nthe most probable path to state j in n steps, minus the\\nleast probable path to state j in n steps, is equal to exactly\\nthe same thing in n minus 1 steps times\\n1 minus 2 alpha. So we just keep on iterating\\nthis over. n, and then we should get this. So to prove this to this, we\\nprove it by induction. We just have to prove the\\ninitial step, that the maximum single transition from l to j,\\nminus the minimum single transition from l to j,\\nis less than or equal to 1 minus 2 alpha. So this one is proved\\nby induction. So as n goes to infinity, notice\\nthat this term is going to go to 0. because alpha is going to\\nbe less than a 1/2. Because if it\\'s not, then we can\\nchoose 1 minus alpha to be this minimum. So if this is going to 0, this\\ntells us the difference between the most probable path\\nminus the least probable path, the fact that we end\\nup in state j. So if we take the limit as n\\ngoes to infinity of both of these, they should equal. Because the difference of this,\\nwe notice that it\\'s going down exponentially in n. So this shows us that this\\nlimit indeed does exist and is equal. We want to prove this first\\nstatement over here. So in order to prove this first\\nstatement, what we\\'re going to do is we\\'re going to\\ntake this i, j transition in n plus 1 transitions. And then we\\'re going to express\\nit as a function of n transitions. So the idea is this. We\\'re going to use the\\nChapman-Kolmogorov equations to have an intermediary step. So in order to do this i to j\\nin n plus 1 steps, the most probable path, we\\'re going to\\ngo to this intermediate step and then on to the final step. In this intermediate step,\\nit\\'s going to be a function of n. So we\\'re going to take one step\\nand then n more steps. So what we\\'re going to do is,\\nthe intuition is, we\\'re going to remove the least\\nprobable path. So we remove that from\\nthe sum in this Chapman-Kolmogorov equation. And then we have the sum\\nof everything else except for that path. And then the sum of everything\\nelse, we\\'re going to bound it. Once we bound it, then we\\nhave this expression. The probability of i to j in n\\nplus 1 steps is going be a function of a max and\\na min over n steps with a bunch of terms. So that\\'s the intuition of\\nhow we\\'re going to do it. So the probability of ij going\\nfrom state i to state j in exactly n plus 1 steps\\nis equal to this. So it\\'s the probability of\\ngoing from i to k, this intermediate step. We\\'re going to take one\\nstep to a state k. And then we\\'re going from\\nk to j in n steps, summing over all k. So this is exactly equal to this\\nwith Chapman-Kolmogorov. So now what happens is\\nwe\\'re going to take-- Before we get to this next step,\\nlet\\'s define this l min to be the state that minimizes\\np of ij, n over i. So l min is going to be the\\nstate that\\'s going to be such that the choices I pick over i\\nthat in n steps I arrive at j that\\'s going to be the\\nleast probable. So this is l min over here. It\\'s the l min that\\nsatisfies this. Then I\\'m going to remove this. So this is one state. l min is\\njust one state that i is going to go to in this first step. So we\\'re going to remove\\nit from the sum. So then, this is just here. So that path goes from i to l\\nmin times l to j in n steps. So remove that one\\npath from here. Now we have the sum over the\\nrest of the cases because we just removed that. So we have ik, kj to\\nn, where k is not equal to that element. So we removed that path, the one\\nthat goes to that state. But p of kj, n, the path that\\ngoes from k to j in n steps, we can just bound this term\\nby the maximum over l from l to j of n. So then we\\'re going to take the\\nmost probable path in n steps such that we end\\nup in state j in n. So this term right here is\\nbounded by this term. Becomes is bounded by this,\\nthat\\'s why we have this less than or equal sign. So we just do two things from\\nthis step, the first step, to the second step. So we took out the path that\\'s\\ngoing to minimize that right at the j-th node in n steps. And then we bounded the rest\\nof this sum by this. So when we sum this all up, this\\nis just a constant here. And ik here is just all the\\nstates that i is going to visit except for this\\none state, l min. Since it\\'s just all of them\\nexcept for that, it\\'s just 1 minus the probability that it\\ngoes from state i to l min. So this sum here is just\\nequal to this sum here. So this arrives here. And this term is still here. So going from here, what\\nhappens is we just to rearrange the terms. So nothing happens right here. It\\'s just rearranging. Now we have this term here. So we look at this term, P\\nfrom i going to l min-- Remember, we chose alpha to be\\nthe minimum single transition probability, single\\ntransition in that probability transition matrix. So i to l has to be\\ngreater than that. But the minus of this has to be\\nless than, the negative has to be less than. So this we can substitute\\nhere. So now we have this. So the maximum over i of this\\nn plus 1 step actually shows you the probability. Because this I can write\\nas an n plus 1 step path from i to j. So if this is less than this\\nentire term, of course I can write the maximum path\\nfrom i to j. It also has to be less of\\nthis because this is satisfied for all i, j. So therefore, we arrive at\\nthis expression here. So now we\\'re kind of in good\\nbusiness because we have the n plus one step at transition, the\\nmaximum path from i to j in n plus 1 steps as a function\\nof n, which is what we wanted, and a function\\nof this alpha. So we repeat that\\nlast statement. And the last one is here,\\nthe last line. So now we have the maximum. So now we want to do is we\\nwant to get the minimum. So we do exactly the same thing,\\nwith the same proof. And with the minimum, what we\\'re\\ngoing to do is we\\'re going to look at the ij\\ntransition in n plus 1 steps. And then what we\\'re going to do\\nis we\\'re going to pull out the maximum this time. So we pull out the most probable\\npath in n steps such that it arrives in state j. Then we play the same game. Would bound everything-- above, this time-- by the\\nminimum of the n step transition probabilities\\nto get to j. So once we do that, we get this\\nexpression, very similar to this one up here. So now we have the maximum path,\\nwhich is n plus 1 steps to j, and the minimum of\\nn plus 1 steps to j. So we could take the difference\\nbetween these two. So if you subtract these\\nequations here, so this first equation minus the second\\nequation, we have this on the right-hand side here and then\\nthese terms over here on the left-hand side. So these terms over here on the\\nleft-hand exactly proves the first line of the lemma. So the first line of\\nthe lemma was here. So now, to prove the second of\\nthe lemma, remember, we\\'re going to prove this\\nby induction. in order to prove this by\\ninduction, we need to be first initial step. So the initial step is this. So if I take the minimum\\ntransition probability from l to j, it has to be greater\\nthan here with the alpha. Because we said that alpha was\\nthe absolute minimum of all the single-step transition\\nprobabilities. Then the maximum transition\\nprobability has to be greater than or equal to\\n1 minus alpha. It\\'s just by definition\\nof what we choose. So therefore, if I take this\\nterm, the maximize minus the minimum is just 1\\nminus 2 alpha. So that\\'s your first step in\\nthe induction process. So we iterate on n. When we iterate on n,\\none arrives at this equation down here. So this shows us from here that\\nif we take the limit as n goes to infinity of this\\nterm, this goes down exponentially in n. And both of these limits are\\ngoing to converge, and they exist, and they\\'re going\\nto be greater than 0. So they\\'ll be greater than 0\\nbecause of our initial state that we chose this path with\\na positive probability. Yeah, go ahead. AUDIENCE: It seems to me that\\nalpha is the minimum, the smallest number in the\\ntransition matrix, right? SHAN-YUAN HO: Alpha is the\\nsmallest number, correct. AUDIENCE: Yeah. How does it fall from\\nthat, like that? So my is, the convergence\\nrate is related to f? SHAN-YUAN HO: Yes,\\nit is, yeah. In general, it doesn\\'t really\\nmatter because it\\'s still going to go down exponentially\\nin n. But it does depend on\\nthat alpha, yes. Any other questions? Yes. AUDIENCE: Is the strength that\\nbound it proportional to the size of that matrix, right? SHAN-YUAN HO: Excuse me? AUDIENCE: The strength\\nof that bound is proportional to the size? I mean, for a very large\\nfinite-state Markov chain, the strength of the bound is going\\nto be somewhat weak because alpha is going to be-- SHAN-YUAN HO: Alpha has\\nto be less than 1/2. AUDIENCE: OK, yes. But the strength of the bound,\\nthough, it\\'s not a very tight bound on max minus min. Because in a large-- SHAN-YUAN HO: Yes. This is just a bound. And the bound is what\\nwhen we took it that minimum-probability path,\\nthe l min, remember? The bound was actually\\nin here. So we took the\\nminimum-probability path in n steps, this l min that minimizes\\nthis over i. And then this is where this less\\nthan or equal to here is just a substitution. Any other questions? So what we know is that what\\nhappens is that these limited-state probabilities\\nexist. So we have a finite\\nergodic chain. So if the probability of the\\nelements in this transition matrix are all greater\\nthan 0, we know that this limit exists. But we know that in general,\\nthat may not be the case. We\\'re going to have some 0\\'s\\nin our transition matrix. So let\\'s go back to the\\narbitrary finite-state ergodic chain with probability\\ntransition matrix P. So in the last slide, we showed that this\\ntransition matrix P of h is positive for h is equal to\\nM minus 1 squared plus 1. So what we do is, we can apply\\nlemma 2 to P of h with this alpha equals to minimum\\ngoing from i to j in exactly h steps. So why is this M minus\\n1 squared plus 1? So in the last lecture-- so what it means is this. So what is says is here. This was an example given\\nin the last lecture. It was a 6-state Markov chain. So what it says is that if n is\\ngreater than or equal to M minus 1 squared plus 1-- in this\\ncase, it\\'s going to be 6. So if n is greater than or equal\\nto 26, then I take P to the 26th power, it means\\nit\\'s greater than zero. That meas if I take P to the\\n26th power, every single element in this transition\\nmatrix is going to be non-zero, which means that you\\ncan go from any state to any state with nonzero probability,\\nas long as n is bigger than that. So basically, in this Markov\\nchain, if you go long enough, long enough. Then I say, OK, I want to go\\nfrom state i to state j in exactly how many steps, there is\\na positive probability that this is going to happen. So how did this bound\\ncome across? Well, for instance, in this\\nchain, if we look at P1,1 so we have here? So I\\'m going to look\\nat the transition starting at state 1. And I want to come back to 1. So you definitely could come\\nback at 6, because these are all positive probability 1. So 6 is possible. So n is equal to\\n6 is possible. So what\\'s the next one\\nthat\\'s possible? n is equal to 11, right? Then the next one is what? 16 is possible, right? So 0 to 5 is impossible, is 0. So if I pick n between 0 and 5,\\nand 7 and 10, you\\'re toast. You can\\'t get back to 1. And so forth. So 18 is possible. 21-- let\\'s see, is 17 possible? Yeah, 17 is also possible. AUDIENCE: Why is 16 possible? SHAN-YUAN HO: So I go around\\nhere twice, and then the last one. Is that right? So if I go from here to here\\nto here to here, if I go twice, and then one more\\nin the final loop. AUDIENCE: That\\'s 12. SHAN-YUAN HO: Oh, it\\'s 12? No. I\\'m going to go this inner\\nloop right here. So if I go from 1 to 2 to 3\\nto 4 to 5 to 6, down to 2. Then I go 3, 4, 5, 6, 1. That\\'s 11, isn\\'t it? So 16 is I\\'m going to go around\\nthe inner loop twice. OK. Go ahead. Question? AUDIENCE: So everything 20 and\\nunder is possible, right? SHAN-YUAN HO: No. Is 25 possible? Tell me how you\\'re going\\nto go 25 on this. You just do the 5\\nloop 5 times. SHAN-YUAN HO: Yeah, but I\\nwant to go from 1 to 1. You\\'re starting in state 1. AUDIENCE: Oh, oh, sorry. OK. SHAN-YUAN HO: 1 to 1, right? AUDIENCE: OK, cool. OK, I see. SHAN-YUAN HO: So you know for\\nthis one that this bound is actually tight. So 25 is impossible. So P1,1 of 25 is equal to 0. There\\'s no way you\\ncan do that. But for 26 on, then you can. So what you\\'re noticing is that\\nyou need this loop of 6 here and that any combination\\nof 5 or 6 is possible. So basically, in this particular\\nexample, if n is equal to 6k plus 5j, where k\\nis greater than or equal to 1-- because I need that final\\nloop to get back-- or j is greater than\\nor equal to 0-- So any combination of this one,\\nthen I can express n. I can go around it to give me\\na positive probability of going from state 1 to state 1. So I\\'m going to prove this\\nusing extremal property. So we\\'re going to take the\\nabsolute worst case. So the absolute worst case is\\nthat for M state finite Markov chain is if have a loop\\nof m and you have a loop of m minus 1. You can\\'t just have\\na loop of m. The problem is now this\\nbecomes periodic. So we have to get rid\\nof the periodicity. If you add a single group here,\\nthat doesn\\'t help you. Then after 6, then it I get\\n7, 8, 9, 10, 11, 12. That didn\\'t have this. So the absolute worst case for\\nan M state chain is going to be something that\\nlooks like this. 1 that goes to 2-- you\\'re\\nforced to go to 2-- so forth, until state M. And\\nthen this M is going to go back to 2 or is going\\nto go back to 1. So in other words, the worst\\ncase is if you have-- n has to be some combination\\nof Mk plus M minus 1 j. So this will be the worst\\npossible case for M state Markov chain. So it\\'ll be Mk plus\\nM minus 1 j. So k has to be greater\\nthan or equal to 1. And then j has to be greater\\nthan or equal to 0, because you need to come back. So I\\'m just looking at the case\\nprobability that I start in state 1 and I come\\nback in state 1. So all right. So how do we get this bound? Well, there is an identity\\nthat says this. If a and b are relatively prime,\\nthen the largest n such that it cannot be written-- so\\nwe want to find the largest n such that ak plus bj-- but this is k and j greater\\nthan or equal to 0-- that it cannot be written\\nin this form. The largest integer that it\\ncannot be written is ab minus a minus b. This takes a little bit to\\nprove, but it\\'s not too hard. If you want to know this proof,\\ncome see me offline after class. This is the largest integer. If n is equal to this,\\nit cannot be written in this form. But if n is greater than\\nthis, then it can. So all we do is substitute M\\nfor a and M minus 1 for b because M and M minus 1\\nare relatively prime. But remember, we have a k here\\nthat has to be greater than or equal to 1. We need at least one k. But this so identity is for\\nk and j greater than 0. So therefore, we have to\\nsubtract out that k. So therefore, we have M times\\nM minus 1, minus M minus M minus 1. But the thing is we have to add\\nthe extra M, because this k is greater than\\nor equal to 1. So we have to add up one of\\nthe M\\'s because of this. So this is just equal to\\nM minus 1, squared. So this number, if n is equal\\nto this, it\\'s the largest number that it cannot be\\nwritten like that. So therefore, we\\nhave to add 1. So that\\'s why the bound\\nis equal to 1. So the upper bound that n can\\nbe written is going to be M minus 1, squared plus 1. AUDIENCE: Why did you add\\nthe 1 at the end? SHAN-YUAN HO: This one? AUDIENCE: No, we\\'ve got to\\ndo the 1 at the end. AUDIENCE: We already\\nhave that in there. SHAN-YUAN HO: Oh, where is it? No, it\\'s in here, right? AUDIENCE: No, it\\'s not here. SHAN-YUAN HO: Did I-- What are you talking about? Where\\'s the 1? AUDIENCE: At the end,\\nthe last equation. SHAN-YUAN HO: This one? AUDIENCE: Yes. SHAN-YUAN HO: OK. This is the \"cannot,\" largest\\nn which you cannot write. You cannot write this. So this bound is tight. It means that this is the\\none that you can. So if n is greater\\nthan or equal to this, then it\\'s possible. This is the largest\\none it cannot. Based on this, it cannot. So we have to add the 1. So therefore, in here,\\nyou could do 26. So starting from 26, 27,\\n28, you can do that. Any questions? AUDIENCE: Relatively prime,\\nwhat do you mean by \"relatively\"? SHAN-YUAN HO: There is a\\ngreatest common divisor of 1. So if we take h here, h is\\ngoing to be positive. So if h is equal to M minus 1,\\nsquared plus 1, then now all the elements are positive. Because we just proved that\\nwe can write this-- every state can be visited by\\nany other state, with positive probability. So we say, looking at P, we know\\nthat P of h is positive for h greater than or\\nequal to this bound. So what we do is we applied this\\nlemma 2 probability to this transition matrix P of h,\\nwhere we have picked alpha-- remember, alpha is the\\nsingle-step transition probability. So instead of the single\\ntransition, we have lumped this P into P to the h power. So it\\'s h steps. Because we proved the result\\nbefore for positive P. So this P to the h is positive, so we\\ntake alpha as the minimum from i to j of P to the\\nh in this matrix. So it doesn\\'t really matter what\\nthe value of alpha is, only that it\\'s going\\nto be positive. And it has to be positive\\nbecause it\\'s a probability. So what happens is, if we follow\\nthe proof of what we just showed in the lemma, then\\nwe show that the maximum path from l to j-- h times M. So M is going\\nto be an integer, so in multiples of h-- this upper limit is going to be\\nequal to the lower limit. So the most probable path\\nis equal to the least probable path. So this is multiple of h\\'s. So if we take this as M goes\\nto infinity, this has got to equal to-- Oops, this should be going\\nto pi sub j, excuse me. This little temple here. And this is going to\\nbe greater than 0. So the problem is now we\\'ve\\nshown it for multiples of h\\'s, what about the h\\'s in between? But the fact is that lemma 1,\\nwe showed that this maximum path from l to j in n is\\nnot increasing in n. So all those states, all those\\npaths, the transition probability for the paths in\\nbetween these multiples of h\\'s, in between them it\\'s\\ngoing to be not increasing in n. So even if we\\'re taking these\\nmultiples of each of h and n here, here, here, and we know\\nthat this limit is increasing, we know that all the ones in\\nbetween them are also going to be increasing to the same limit\\nbecause of lemma 1. To remember, the maximum is\\ngoing to be not increasing, and the minimum is going to be non-decreasing in any one path. So this must have the\\nsame limit as this multiple of this. So the same limit applies. So any questions on this? So this is how we prove it for\\nthe arbitrary finite-state ergodic chain when we have some\\n0 probability transition elements in the matrix P. So\\nthe proof is the same. So now for ergodic unichain. So we see that this limit as n\\napproaches infinity from i to j of n is going to just end up\\nin the steady-state transition pi of j for all i. So it doesn\\'t matter what\\nyour initial state is. As n goes to infinity of this\\npath, as this Markov chain goes on and on, you will end up\\nin state j with probability pi sub j, where pi is this\\nprobability vector. So now we have this steady-state\\nvector, and then we can solve for the\\nsteady-state vector solution. So this pi P is equal to pi. Yeah? Go ahead. AUDIENCE: Where did you prove\\nthat the sum of all the pi j\\'s equal to one? Because you say that we\\nproved that this is the probability vector. But did prove only that\\nit is non-negative? SHAN-YUAN HO: It\\'s\\nnon-negative. But the thing is because as n\\ngoes to infinity, you have to land up someone, right? This is a finite-state\\nMarkov chain. You have to be somewhere. And the fact that you have to be\\nsomewhere, your whole state space has to add up to 1. Because it\\'s a constant,\\nremember? For every j, as n goes to\\ninfinity, it goes to pi sub j. So you have that for\\nevery single state. And then you have to\\nend up somewhere. So if you have to end up\\nsomewhere, the space has to add up to one. Yeah, good question. So why are we interested\\nin this pi sub j? The question is that because\\nin this recurrent class, it tells us that as this goes to\\ninfinity, we see this sequence of states going back and\\nforth, back and forth. And we know that as n goes\\nto infinity, we have some probability, pi sub j, of\\nlanding in state j, pi sub i of landing in state\\ni, and so forth. So it says that in the n step,\\nas n goes to infinity, that this is the fraction of time\\nthat, actually, that state is going to be visited. Because at each step, you have\\nto make a transition. So it\\'s kind of the expected\\nnumber of times per unit time. So it\\'s divide by n. It\\'s going to be that fraction\\nof time that you\\'re going to visit that state. It\\'s the fraction of time\\nthat you\\'re going to be in that state. It\\'s this limiting state as\\nn gets very, very large. So we will see that in the next\\nfew chapters when we do renewal theory that this will\\ncome into useful play. And we give a slightly different\\nviewpoint of it. So it\\'s very easy to extend this\\nresult to a more general class of ergodic unichains. So remember the ergodic\\nunichains, now we have increased these transient\\nstates. So before, we proved this. We just proved it for it\\ncontains exactly one class. It\\'s aperiodic, so we have no\\ncycles, no periodicity in this Markov chain. And so we know that the\\nsteady-state transition probabilities have a limit. And the upper limit and the\\nlower limit of these paths as they go to infinity-- in fact, they end up in\\na particular state-- has a limit. And we have this steady-state\\nprobability vector that describes this. So now we have these\\ntransient states. So these transient states of\\nthis Markov chain, what happens is there exists a path\\nthat this transient state is going to go to a recurrent\\nstate. So once it leaves this transient\\nstate, it goes to recurrent state. It\\'s never going to come back. So there is some probability,\\nalpha, of leaving the class at each step. So there\\'s some transition\\nprobability in this transient state that\\'s going\\nto be alpha. And the probability of remaining\\nin this transient state is just 1 minus\\nalpha to the n. And this goes down\\nexponentially. So what this says is that\\neventually, as n gets very large, it\\'s very, very hard to\\nstay in that transient state. So it\\'s going to go out of\\nthe transient state. And then it will go into\\nthe recurrent class. So when one does the analysis\\nfor this, what happens in the probability in this steady-state\\nvector is those transient states, this pi,\\nwill be equal to 0. So this distribution is only\\ngoing to be non-zero for recurrent states in this\\nMarkov chains. And the transient states will\\nhave probability equal to 0. In the notes, they just\\nextend the argument. But you need a little bit\\nmore care to show this. And it divides the transient\\nstates into a block and then the recurrent classes into\\nanother block and then shows that these transient states\\'\\nlimiting probability is going to go to 0. So let\\'s see. So this says just what I said,\\nthat these transient states decay exponentially, and one\\nof the paths will be taken, eventually, out of it. So for ergodic unichains, the\\nergodic class is eventually entered, and then steady state\\nin that class is reached. So every state j, we\\nhave exactly this. The maximum path from\\ni to j in n steps-- and the minimum path. We look at the minimum path in\\nn steps and the maximum path in n steps. And for each n, we take the\\nlimit as n goes to infinity. These guys, these limits are\\nexactly equal, and it equals to this pi sub j, which is\\nequal to the j state. So your initial states, how you\\nwent the paths that you have gone is completely\\nwiped out. And all that matters is\\nthis final state, as n gets very large. So the difference here is that\\npi sub j equals 0 for each transient state, and it\\'s\\ngreater than 0 for the recurrent state. So other finite Markov chains. So we can consider a\\nMarkov chain with several ergodic classes. Because we just considered it\\nwith one ergodic class. So if the classes don\\'t\\ncommunicate, then you just consider it separately. So you figure out the\\nsteady-state transition probabilities for each of\\nthe classes separately. But if you have to insist on\\nanalyzing the entire chain P, then this P will have m\\nindependent steady-state vectors and one non-zero\\nin each class. So this P sub n is still going\\nto converge, but the rows are not going to be the same. So basically, you\\'re going\\nto have blocks. So if you have one class, say 1\\nthrough k is going to be in one class, and then k through\\nl is going to be another class, and then l through z is\\ngoing to another class, you have a block. So this steady-state vector\\nis going to be in blocks. So you can see the recurring\\nclasses only communicate within themselves. Because these don\\'t communicate, so they\\'re separate. So you could have a lot of 0\\'s\\nin limiting state, if you look at this, P sub n goes\\nto infinity. So there m set of rows,\\none for each class. And a row for each class k\\nwill be non-zero for the elements of that class. So then finally, if we\\nhave periodicity. So now if we have a periodic\\nrecurrent chain with period d. We had the two where it\\'s\\njust a period of 2. So with periodicity, what you\\ndo is you\\'re going to divide these classes into d\\ndifferent states. So you have to go\\nto one state-- So if there\\'s d states, this is\\na period of d, you separate or you partition the states into\\nd of them, d subclasses, with a cycle rotation\\nbetween them. So basically, each time unit,\\nyou have to go from one class to the next class. And then we do that, then for\\neach class, you could have the limiting-state probability. So in other words, you are\\nlooking at this transition matrix, pi d. Because when it cycles, it\\ntotally depends on which one you start out at. But if you look at the d\\nintervals, then that becomes the ergodic class by itself. And there are exactly\\nd of them. So the limit as n approaches\\ninfinity of P of nd, this thing also exists, but exists in\\nthe subclass sense of there is d subclasses if it\\nhas a period of d. So that means a steady state\\nis reached within each subclass, but the chain\\nrotates from one subclass to another. Yeah, go ahead. AUDIENCE: In this case, if we\\ndo a simple check with 1 and 2, with 1 and 1, it\\ndoesn\\'t converge. SHAN-YUAN HO: No, it does. It is 1, converges to 1. So it\\'s 1, and then it\\'s\\ngoing to be 1. AUDIENCE: It\\'s 1, 1,\\n1, 1, 1, 1, 1, 1. So you go here? Like, it\\'s reached--? SHAN-YUAN HO: No, no. It converges for here. But this d is equal to\\n2, in that case. So you have to do nd,\\nso you\\'ve got to look at P squared. So if I look at P squared,\\nI\\'m always a 1-- 1, 1, 1, 1, 1, 1, 1, 1. That\\'s converging. The other one is 2,\\n2, 2, 2, 2, 2. That\\'s also converging. OK. So is there any other questions\\nabout this? OK, that\\'s it. Thank you.'], Target: 1\n",
            "Features: [b\"The following content is\\nprovided under a Creative Commons license.\\nYour support will help MIT OpenCourseWare continue to offer\\nhigh quality educational resources for free.\\nTo make a donation or to view additional materials from\\nhundreds of MIT courses, visit MIT OpenCourseWare at\\nocw.mit.edu. So, let me remind you,\\nyesterday we've defined and started to compute line\\nintegrals for work as a vector field along a curve.\\nSo, we have a curve in the plane, C.\\nWe have a vector field that gives us a vector at every\\npoint. And, we want to find the work\\ndone along the curve. So, that's the line integral\\nalong C of F dr, or more geometrically,\\nline integral along C of F.T ds where T is the unit tangent\\nvector, and ds is the arc length\\nelement. Or, in coordinates,\\nthat they integral of M dx N dy where M and N are the components\\nof the vector field. OK, so -- Let's do an example\\nthat will just summarize what we did yesterday,\\nand then we will move on to interesting observations about\\nthese things. So, here's an example we are\\ngoing to look at now. Let's say I give you the vector\\nfield yi plus xj. So, it's not completely obvious\\nwhat it looks like, but here is a computer plot of\\nthat vector field. So, that tells you a bit what\\nit does. It points in all sorts of\\ndirections. And, let's say we want to find\\nthe work done by this vector field.\\nIf I move along this closed curve, I start at the origin.\\nBut, I moved along the x-axis to one.\\nThat move along the unit circle to the diagonal,\\nand then I move back to the origin in a straight line.\\nOK, so C consists of three parts -- -- so that you enclose\\na sector of a unit disk -- -- corresponding to angles between\\nzero and 45\\xef\\xbf\\xbd. So, to compute this line\\nintegral, all we have to do is we have set up three different\\nintegrals and add that together. OK, so we need to set up the\\nintegral of y dx plus x dy for each of these pieces.\\nSo, let's do the first one on the x-axis.\\nWell, one way to parameterize that is just use the x variable.\\nAnd, say that because we are on the, let's see,\\nsorry, we are going from the origin to (1,0).\\nWell, we know we are on the x-axis.\\nSo, y there is actually just zero.\\nAnd, the variable will be x from zero to one.\\nOr, if you prefer, you can parameterize things,\\nsay, x equals t for t from zero to one, and y equals zero.\\nWhat doesn't change is y is zero, and therefore,\\ndy is also zero. So, in fact,\\nwe are integrating y dx x dy, but that becomes,\\nwell, zero dx 0, and that's just going to give\\nyou zero. OK, so there's the line\\nintegral. Here, it's very easy to compute.\\nOf course, you can also do it geometrically because\\ngeometrically, you can see in the picture\\nalong the x-axis, the vector field is pointing\\nvertically. If I'm on the x-axis,\\nmy vector field is actually in the y direction.\\nSo, it's perpendicular to my curve.\\nSo, the work done is going to be zero.\\nF dot T will be zero. OK, so F dot T is zero,\\nso the integral is zero. OK, any questions about this\\nfirst part of the calculation? No? It's OK?\\nOK, let's move on to more interesting part of it.\\nLet's do the second part, which is a portion of the unit\\ncircle. OK, so I should have drawn my\\npicture. And so now we are moving on\\nthis part of the curve that's C2.\\nAnd, of course we have to choose how to express x and y in\\nterms of a single variable. Well, most likely,\\nwhen you are moving on a circle, you are going to use the\\nangle along the circle to tell you where you are.\\nOK, so we're going to use the angle theta as a parameter.\\nAnd we will say, we are on the unit circle.\\nSo, x is cosine theta and y is sine theta.\\nWhat's the range of theta? Theta goes from zero to pi over\\nfour, OK? So, whenever I see dx,\\nI will replace it by, well, the derivative of cosine\\nis negative sine. So, minus sine theta d theta,\\nand dy, the derivative of sine is cosine.\\nSo, it will become cosine theta d theta.\\nOK, so I'm computing the integral of y dx x dy.\\nThat means -- -- I'll be actually computing the integral\\nof, so, y is sine theta. dx, that's negative sine theta\\nd theta plus x cosine. dy is cosine theta d theta from\\nzero to pi/4. OK, so that's integral from\\nzero to pi / 4 of cosine squared minus sine squared.\\nAnd, if you know your trig, then you should recognize this\\nas cosine of two theta. OK, so that will integrate to\\none half of sine two theta from zero to pi over four,\\nsorry. And, sine pi over two is one.\\nSo, you will get one half. OK, any questions about this\\none? No?\\nOK, then let's do the third one. So, the third guy is when we\\ncome back to the origin along the diagonal.\\nOK, so we go in a straight line from this point.\\nWhere's this point? Well, this point is one over\\nroot two, one over root two. And, we go back to the origin.\\nOK, so we need to figure out a way to express x and y in terms\\nof the same parameter. So, one way which is very\\nnatural would be to just say, well, let's say we move from\\nhere to here over time. And, at time zero, we are here.\\nAt time one, we are here. We know how to parameterize\\nthis line. So, what we could do is say,\\nlet's parameterize this line. So, we start at one over root\\ntwo, and we go down by one over root two in time one.\\nAnd, same with y. That's actually perfectly fine.\\nBut that's unnecessarily complicated.\\nOK, why is a complicated? Because we will get all of\\nthese expressions. It would be easier to actually\\njust look at motion in this direction and then say,\\nwell, if we have a certain work if we move from here to here,\\nthen the work done moving from here to here is just going to be\\nthe opposite, OK?\\nSo, in fact, we can do slightly better by\\njust saying, well, we'll take x = t,\\ny = t. t from zero to one over root\\ntwo, and take, well, sorry,\\nthat gives us what I will call minus C3, which is C3 backwards.\\nAnd then we can say the integral for work along minus C3\\nis the opposite of the work along C3.\\nOr, if you're comfortable with integration where variables go\\ndown, then you could also say that t\\njust goes from one over square root of two down to zero.\\nAnd, when you set up your integral, it will go from one\\nover root two to zero. And, of course,\\nthat will be the negative of the one from zero to one over\\nroot two. So, it's the same thing.\\nOK, so if we do it with this parameterization,\\nwe'll get that, well of course,\\ndx is dt, dy is dt. So, the integral along minus C3\\nof y dx plus x dy is just the integral from zero to one over\\nroot two of t dt plus t dt. Sorry, I'm messing up my\\nblackboard, OK, which is going to be,\\nwell, the integral of 2t dt, which is t2 between these\\nbounds, which is one half. That's the integral along minus\\nC3, along the reversed path. And, if I want to do it along\\nC3 instead, then I just take the negative.\\nOr, if you prefer, you could have done it directly\\nwith integral from one over root two, two zero,\\nwhich gives you immediately the negative one half.\\nOK, so at the end, we get that the total work --\\n-- was the sum of the three line integrals.\\nI'm not writing after dr just to save space.\\nBut, zero plus one half minus one half, and that comes out to\\nzero. So, a lot of calculations for\\nnothing. OK, so that should give you\\noverview of various ways to compute line integrals.\\nAny questions about all that? No? OK.\\nSo, next, let me tell you about how to avoid computing like\\nintegrals. Well, one is easy:\\ndon't take this class. But that's not,\\nso here's another way not to do it, OK?\\nSo, let's look a little bit about one kind of vector field\\nthat actually we've encountered a few weeks ago without saying\\nit. So, we said when we have a\\nfunction of two variables, we have the gradient vector.\\nWell, at the time, it was just a vector.\\nBut, that vector depended on x and y.\\nSo, in fact, it's a vector field.\\nOK, so here's an interesting special case.\\nSay that F, our vector field is actually the gradient of some\\nfunction. So, it's a gradient field.\\nAnd, so f is a function of two variables, x and y,\\nand that's called the potential for the vector field.\\nThe reason is, of course, from physics.\\nIn physics, you call potential, electrical potential or\\ngravitational potential, the potential energy.\\nThis function of position that tells you how much actually\\nenergy stored somehow by the force field, and this gradient\\ngives you the force. Actually, not quite.\\nIf you are a physicist, that the force will be negative\\nthe gradient. So, that means that physicists'\\npotentials are the opposite of a mathematician's potential.\\nOkay? So it's just here to confuse\\nyou. It doesn't really matter all\\nthe time. So to make things simpler we\\nare using this convention and you just put a minus sign if you\\nare doing physics. So then I claim that we can\\nsimplify the evaluation of the line integral for work.\\nPerhaps you've seen in physics, the work done by,\\nsay, the electrical force, is actually given by the change\\nin the value of a potential from the starting point of the ending\\npoint, or same for gravitational force.\\nSo, these are special cases of what's called the fundamental\\ntheorem of calculus for line integrals.\\nSo, the fundamental theorem of calculus, not for line\\nintegrals, tells you if you integrate a derivative,\\nthen you get back the function. And here, it's the same thing\\nin multivariable calculus. It tells you,\\nif you take the line integral of the gradient of a function,\\nwhat you get back is the function. OK,\\nso -- -- the fundamental theorem of calculus for line\\nintegrals -- -- says if you integrate a vector field that's\\nthe gradient of a function along a curve,\\nlet's say that you have a curve that goes from some starting\\npoint, P0, to some ending point, P1.\\nAll you will get is the value of F at P1 minus the value of F\\nat P0. OK, so, that's a pretty nifty\\nformula that only works if the field that you are integrating\\nis a gradient. You know it's a gradient,\\nand you know the function, little f.\\nI mean, we can't put just any vector field in here.\\nWe have to put the gradient of F.\\nSo, actually on Tuesday we'll see how to decide whether a\\nvector field is a gradient or not,\\nand if it is a gradient, how to find the potential\\nfunction. So, we'll cover that.\\nBut, for now we need to try to figure out a bit more about\\nthis, what it says, what it means physically,\\nhow to think of it geometrically,\\nand so on. So, maybe I should say,\\nif you're trying to write this in coordinates,\\nbecause that's also a useful way to think about it,\\nif I give you the line integral along C,\\nso, the gradient field, the components are f sub x and\\nf sub y. So, it means I'm actually\\nintegrating f sub x dx plus f sub y dy.\\nOr, if you prefer, that's the same thing as\\nactually integrating df. So, I'm integrating the\\ndifferential of a function, f.\\nWell then, that's the change in F.\\nAnd, of course, if you write it in this form,\\nthen probably it's quite obvious to you that this should\\nbe true. I mean, in this form,\\nactually it's the same statement as in single variable\\ncalculus. OK, and actually that's how we\\nprove the theorem. So, let's prove this theorem.\\nHow do we prove it? Well, let's say I give you a\\ncurve and I ask you to compute this integral.\\nHow will you do that? Well, the way you compute the\\nintegral actually is by choosing a parameter, and expressing\\neverything in terms of that parameter.\\nSo, we'll set, well, so we know it's f sub x\\ndx plus f sub y dy. And, we'll want to parameterize\\nC in the form x equals x of t. y equals y of t.\\nSo, if we do that, then dx becomes x prime of t\\ndt. dy becomes y prime of t dt.\\nSo, we know x is x of t. That tells us dx is x prime of\\nt dt. y is y of t gives us dy is y\\nprime of t dt. So, now what we are integrating\\nactually becomes the integral of f sub x times dx dt plus f sub y\\ntimes dy dt times dt. OK, but now,\\nhere I recognize a familiar guy.\\nI've seen this one before in the chain rule.\\nOK, this guy, by the chain rule,\\nis the rate of change of f if I take x and y to be functions of\\nt. And, I plug those into f.\\nSo, in fact, what I'm integrating is df dt\\nwhen I think of f as a function of t by just plugging x and y as\\nfunctions of t. And so maybe actually I should\\nnow say I have sometimes t goes from some initial time,\\nlet's say, t zero to t one. And now, by the usual\\nfundamental theorem of calculus, I know that this will be just\\nthe change in the value of f between t zero and t one. OK, so integral from t zero to\\none of (df /dt) dt, well, that becomes f between t\\nzero and t one. f of what?\\nWe just have to be a little bit careful here.\\nWell, it's not quite f of t. It's f seen as a function of t\\nby putting x of t and y of t into it.\\nSo, let me read that carefully. What I'm integrating to is f of\\nx of t and y of t. Does that sound fair?\\nYeah, and so, when I plug in t1,\\nI get the point where I am at time t1.\\nThat's the endpoint of my curve. When I plug t0,\\nI will get the starting point of my curve, p0.\\nAnd, that's the end of the proof.\\nIt wasn't that hard, see? OK, so let's see an example.\\nWell, let's look at that example again.\\nSo, we have this curve. We have this vector field.\\nCould it be that, by accident,\\nthat vector field was a gradient field?\\nSo, remember, our vector field was y,\\nx. Can we think of a function\\nwhose derivative with respect to x is y, and derivative with\\nrespect to y is x? Yeah, x times y sounds like a\\ngood candidate where f( x, y) is xy.\\nOK, so that means that the line\\nintegrals that we computed along these things can be just\\nevaluated from just finding out the values of f at the endpoint?\\nSo, here's version two of my plot where I've added the\\ncontour plot of a function, x, y on top of the vector\\nfield. Actually, they have a vector\\nfield is still pointing perpendicular to the level\\ncurves that we have seen, just to remind you.\\nAnd, so now, when we move,\\nnow when we move, the origin is on the level\\ncurve, f equals zero. And, when we start going along\\nC1, we stay on f equals zero. So, there's no work.\\nThe potential doesn't change. Then on C2, the potential\\nincreases from zero to one half. The work is one half.\\nAnd then, on C3, we go back down from one half\\nto zero. The work is negative one half.\\nSee, that was much easier than computing.\\nSo, for example, the integral along C2 is\\nactually just, so, C2 goes from one zero to\\none over root two, one over root two.\\nSo, that's one half minus zero, and that's one half,\\nOK, because C2 was going here. And, at this point, f is zero.\\nAt that point, f is one half. And, similarly for the others,\\nand of course when you sum, you get zero because the total\\nchange in f when you go from here,\\nto here, to here, to here, eventually you are back at the\\nsame place. So, f hasn't changed.\\nOK, so that's a neat trick. And it's important conceptually\\nbecause a lot of the forces are gradients of potentials,\\nnamely, gravitational force, electric force.\\nThe problem is not every vector field is a gradient.\\nA lot of vector fields are not gradients.\\nFor example, magnetic fields certainly are\\nnot gradients. So -- -- a big warning:\\neverything today only applies if F is a gradient field.\\nOK, it's not true otherwise. OK, still, let's see,\\nwhat are the consequences of the fundamental theorem?\\nSo, just to put one more time this disclaimer,\\nif F is a gradient field -- -- then what do we have?\\nWell, there's various nice features of work done by\\ngradient fields that are not too far off the vector fields.\\nSo, one of them is this property of path independence.\\nOK, so the claim is if I have a line integral to compute,\\nthat it doesn't matter which path I take as long as it goes\\nfrom point a to point b. It just depends on the point\\nwhere I start and the point where I end.\\nAnd, that's certainly false in general, but for a gradient\\nfield that works. So if I have a point,\\nP0, a point, P1,\\nand I have two different paths that go there,\\nsay, C1 and C2, so they go from the same point\\nto the same point but in different ways,\\nthen in this situation, the line integral along C1 is\\nequal to the line integral along C2.\\nWell, actually, let me insist that this is only\\nfor gradient fields by putting gradient F in here,\\njust so you don't get tempted to ever use this for a field\\nthat's not a gradient field -- -- if C1 and C2 have the same\\nstart and end point. OK, how do you prove that?\\nWell, it's very easy. We just use the fundamental\\ntheorem. It tells us,\\nif you compute the line integral along C1,\\nit's just F at this point minus F at this point.\\nIf you do it for C2, well, the same.\\nSo, they are the same. And for that you don't actually\\neven need to know what little f is.\\nYou know in advance that it's going to be the same.\\nSo, if I give you a vector field and I tell you it's the\\ngradient of mysterious function but I don't tell you what the\\nfunction is and you don't want to find out,\\nyou can still use path independence,\\nbut only if you know it's a gradient. OK, I guess this one is dead.\\nSo, that will stay here forever because nobody is tall enough to\\nerase it. When you come back next year\\nand you still see that formula, you'll see.\\nYes, but there's no useful information here.\\nThat's a good point. OK, so what's another\\nconsequence? So, if you have a gradient\\nfield, it's what's called conservative.\\nOK, so what a conservative field?\\nWell, the word conservative comes from the idea in physics;\\nif the conservation of energy. It tells you that you cannot\\nget energy for free out of your force field.\\nSo, what it means is that in\\nparticular, if you take a closed\\ntrajectory, so a trajectory that goes from\\nsome point back to the same point,\\nso, if C is a closed curve, then the work done along C --\\n-- is zero. OK, that's the definition of\\nwhat it means to be conservative.\\nIf I take any closed curve, the work will always be zero.\\nOn the contrary, not conservative means\\nsomewhere there is a curve along which the work is not zero.\\nIf you find a curve where the work is zero,\\nthat's not enough to say it's conservative.\\nYou have show that no matter what curve I give you,\\nif it's a closed curve, it will always be zero.\\nSo, what that means concretely is if you have a force field\\nthat conservative, then you cannot build somehow\\nsome perpetual motion out of it. You can't build something that\\nwill just keep going just powered by that force because\\nthat force is actually not providing any energy.\\nAfter you've gone one loop around, nothings happened from\\nthe point of view of the energy provided by that force.\\nThere's no work coming from the force,\\nwhile if you have a force field that's not conservative than you\\ncan try to actually maybe find a loop where the work would be\\npositive. And then, you know,\\nthat thing will just keep running.\\nSo actually, if you just look at magnetic\\nfields and transformers or power adapters,\\nand things like that, you precisely extract energy\\nfrom the magnetic field. Of course, I mean,\\nyou actually have to take some power supply to maintain the\\nmagnetic fields. But, so a magnetic field,\\nyou could actually try to get energy from it almost for free.\\nA gravitational field or an electric field,\\nyou can't. OK, so and now why does that\\nhold? Well, if I have a gradient\\nfield, then if I try to compute this\\nline integral, I know it will be the value of\\nthe function at the end point minus the value at the starting\\npoint. But, they are the same.\\nSo, the value is the same. So, if I have a gradient field,\\nand I do the line integral, then I will get f at the\\nendpoint minus f at the starting point.\\nBut, they're the same point, so that's zero.\\nOK, so just to reinforce my warning that not every field is\\na gradient field, let's look again at our\\nfavorite vector field from yesterday.\\nSo, our favorite vector field yesterday was negative y and x.\\nIt's a vector field that just rotates around the origin\\ncounterclockwise. Well, we said,\\nsay you take just the unit circle -- -- for example,\\ncounterclockwise. Well, remember we said\\nyesterday that the line integral of F dr, maybe I should say F\\ndot T ds now, because the vector field is\\ntangent to the circle. So, on the unit circle,\\nF is tangent to the curve. And so, F dot T is length F\\ntimes, well, length T. But, T is a unit vector.\\nSo, it's length F. And, the length of F on the\\nunit circle was just one. So, that's the integral of 1 ds.\\nSo, it's just the length of the circle that's 2 pi.\\nAnd 2 pi is definitely not zero. So, this vector field is not\\nconservative. And so, now we know actually\\nit's not the gradient of anything because if it were a\\ngradient, then it would be conservative and it's not.\\nSo, it's an example of a vector field that is not conservative.\\nIt's not path independent either by the way because,\\nsee, if I go from here to here along the upper half circle or\\nalong the lower half circle, in one case I will get pi.\\nIn the other case I will get negative pi.\\nI don't get the same answer, and so on, and so on.\\nIt just fails to have all of these properties.\\nSo, maybe I will write that down.\\nIt's not conservative, not path independent.\\nIt's not a gradient. It doesn't have any of these\\nproperties. OK, any questions?\\nYes? How do you determine whether\\nsomething is a gradient or not? Well, that's what we will see\\non Tuesday. Yes?\\nIs it possible that it's conservative and not path\\nindependent, or vice versa? The answer is no;\\nthese two properties are equivalent, and we are going to\\nsee that right now. At least that's the plan.\\nOK, yes? Let's see, so you said if it's\\nnot path independent, then we cannot draw level\\ncurves that are perpendicular to it at every point.\\nI wouldn't necessarily go that far.\\nYou might be able to draw curves that are perpendicular to\\nit. But they won't be the level\\ncurves of a function for which this is the gradient.\\nI mean, you might still have, you know,\\nif you take, say, take his gradient field and\\nscale it that in strange ways, you know, multiply by two in\\nsome places, by one in other places,\\nby five and some other places, you will get something that\\nwon't be conservative anymore. And it will still be\\nperpendicular to the curves. So, it's more subtle than that,\\nbut certainly if it's not conservative then it's not a\\ngradient, and you cannot do what we said.\\nAnd how to decide whether it is or not, they'll be Tuesday's\\ntopic. So, for now,\\nI just want to figure out again actually, let's now state all\\nthese properties -- Actually, let me first do one minute of\\nphysics. So, let me just tell you again\\nwhat's the physics in here. So, it's a force field is the\\ngradient of a potential -- -- so, I'll still keep my plus\\nsigns. So, maybe I should say this is\\nminus physics. [LAUGHTER]\\nSo, the work of F is the change in value of potential from one\\nendpoint to the other endpoint. [PAUSE ] And -- -- so,\\nyou know, you might know about gravitational fields,\\nor electrical -- -- fields versus gravitational -- -- or\\nelectrical potential. And, in case you haven't done\\nany 8.02 yet, electrical potential is also\\ncommonly known as voltage. It's the one that makes it hurt\\nwhen you stick your fingers into the socket.\\n[LAUGHTER] Don't try it. OK, and so now,\\nconservativeness means no energy can be extracted for free\\n-- -- from the field. You can't just have, you know,\\na particle moving in that field and going on in definitely,\\nfaster and faster, or if there's actually\\nfriction, then keep moving.\\nSo, total energy is conserved. And, I guess,\\nthat's why we call that conservative.\\nOK, so let's end with the recap of various equivalent\\nproperties. OK, so the first property that\\nI will have for a vector field is that it's conservative.\\nSo, to say that a vector field with conservative means that the\\nline integral is zero along any closed curve.\\nMaybe to clarify, sorry, along all closed curves,\\nOK, every closed curve; give me any closed curve,\\nI get zero. So, now I claim this is the\\nsame thing as a second property, which is that the line integral\\nof F is path independent. OK, so that means if I have two\\npaths with the same endpoint, then I will get always the same\\nanswer. Why is that equivalent?\\nWell, let's say that I am path independent.\\nIf I am path independent, then if I take a closed curve,\\nwell, it has the same endpoints as just the curve that doesn't\\nmove at all. So, path independence tells me\\ninstead of going all around, I could just stay where I am.\\nAnd then, the work would just be zero.\\nSo, if I path independent, tonight conservative.\\nConversely, let's say that I'm just conservative and I want to\\ncheck path independence. Well, so I have two points,\\nand then I had to paths between that.\\nI want to show that the work is the same.\\nWell, how I do that? C1 and C2, well,\\nI observe that if I do C1 minus C2, I get a closed path.\\nIf I go first from here to here, and then back along that\\none, I get a closed path. So, if I am conservative,\\nI should get zero. But, if I get zero on C1 minus\\nC2, it means that the work on C1 and the work on C2 are the same.\\nSee, so it's the same. It's just a different way to\\nthink about the situation. More things that are\\nequivalent, I have two more things to say.\\nThe third one, it's equivalent to F being a\\ngradient field. OK, so this is equivalent to\\nthe third property. F is a gradient field.\\nWhy? Well, if we know that it's a\\ngradient field, that we've seen that we get\\nthese properties out of the fundamental theorem.\\nThe question is, if I have a conservative,\\nor path independent vector field, why is it the gradient of\\nsomething? OK, so this way is a\\nfundamental theorem. That way, well,\\nso that actually, let me just say that will be\\nhow we find the potential. So, how do we find potential?\\nWell, let's say that I know the value of my potential here.\\nActually, I get to choose what it is.\\nRemember, in physics, the potential is defined up to\\nadding or subtracting a constant.\\nWhat matters is only the change in potential.\\nSo, let's say I know my potential here and I want to\\nknow my potential here. What do I do?\\nWell, I take my favorite particle and I move it from here\\nto here. And, I look at the work done.\\nAnd that tells me how much potential has changed.\\nSo, that tells me what the potential should be here.\\nAnd, this does not depend on my choice of path because I've\\nassumed that I'm path independence.\\nSo, that's who we will do on Tuesday.\\nAnd, let me just state the fourth property that's the same.\\nSo, all that stuff is the same as also four.\\nIf I look at M dx N dy is what's called an exact\\ndifferential. So, what that means,\\nan exact differential, means that it can be put in the\\nform df for some function, f,\\nand just reformulating this thing, right,\\nbecause I'm saying I can just put it in the form f sub x dx\\nplus f sub y dy, which means my vector field was\\na gradient field. So, these things are really the\\nsame. OK, so after the weekend,\\non Tuesday we will actually figure out how to decide whether\\nthese things hold or not, and how to find the potential.\"], Target: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtB1XyTCiiCe",
        "colab_type": "text"
      },
      "source": [
        "#Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6PhqqnxYZE0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = tfds.features.text.Tokenizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JciR0EiSYsWb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocabulary_set = set()\n",
        "lectures.pop('label')\n",
        "text = tf.data.Dataset.from_tensor_slices(lectures.values)\n",
        "for text_tensor in text:\n",
        "  some_tokens = tokenizer.tokenize(text_tensor.numpy()[0])\n",
        "  vocabulary_set.update(some_tokens)\n",
        "vocab_size = len(vocabulary_set)\n",
        "encoder = tfds.features.text.TokenTextEncoder(vocabulary_set)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CP53G4QvTkwA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = train.map(encode_map_fn)\n",
        "test = test.map(encode_map_fn)\n",
        "#val = val.map(encode_map_fn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ne1QAPUhd3lG",
        "colab_type": "code",
        "outputId": "ac626a48-a93d-471a-8fd6-090a08c5a2e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "input = train.take(1)\n",
        "next(iter(input))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(1298,), dtype=int64, numpy=array([ 6143, 16144,   120, ..., 14718, 16891,  1984])>,\n",
              " <tf.Tensor: shape=(), dtype=int64, numpy=0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9l_rrgueYQy",
        "colab_type": "text"
      },
      "source": [
        "#Decode"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sL5yd-NYb6f",
        "colab_type": "code",
        "outputId": "9e20103f-edc9-43e9-869d-85497670397c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        }
      },
      "source": [
        "example_text = test.take(1);\n",
        "example_text = next(iter(example_text))[0].numpy()\n",
        "encoded_example = encoder.decode(example_text)\n",
        "print(encoded_example)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The following content is provided under a Creative Commons license Your support will help MIT OpenCourseWare continue to offer high quality educational resources for free To make a donation or to view additional materials from hundreds of MIT courses visit MIT OpenCourseWare at ocw mit edu PROFESSOR Now today we are continuing with this last unit Unit 5 continued The informal title of this unit is Dealing With Infinity That s really the extra little piece that we re putting in to our discussions of things like limits and integrals To start out with today I d like to recall for you L Hopital s Rule And in keeping with the spirit here we re just going to do the infinity infinity case I stated this a little differently last time and I want to state it again today Just to make clear what the hypotheses are and what the conclusion is We start out with really three hypotheses Two of them are kind of obvious The three hypotheses are that f x tends to infinity g x tends to infinity that s what it means to be in this infinity infinity case And then the last assumption is that f x g x tends to a limit L And this is all as x tends to some a Some limit a And then the conclusion is that f x g x also tends to L as x goes to a Now so that s the way it is So it s three limits But presumably these are obvious and this one is exactly what we were going to check anyway Gives us this one limit So that s the statement And then the other little interesting point here which is consistent with this idea of dealing with infinity is that a equals plus or minus infinity and L equals plus or minus infinity are OK That is the numbers capital L the limit capital L and the number a can also be infinite Now in recitation yesterday you should have discussed something about rates of growth which follow from what I said in lecture last time and also maybe from some more detailed discussions that you had in recitation And I m going to introduce a notation to compare functions Namely we say that f x is a lot less than g x So this means that the limit as it goes to infinity this tends to 0 As x goes to infinity this would be So this is a notation a new notation for us f is a lot less than g And it s meant to be read only asymptotically It s only in the limit as x goes to infinity that this happens And implicitly here I m always assuming that these are positive quantities f and g are positive What you saw in recitation was that you can make a systematic comparison of all the standard functions that we know about For example the ln function goes to infinity But a lot more slowly than x to a power A lot more slowly then e x A lot more slowly than say e x 2 So this one is slow This one is moderate And this one is fast And this one is very fast Going to infinity Tends to infinity and this is of course as x goes to infinity All of them go to infinity but at quite different rates And analogous to this and today we re going to be doing this needing to do this quite a bit is rates of decay which are more or less the opposite of rates of growth So rates of decay are rates at which things tend to 0 So the rate of decay and for that I m just going to take reciprocals of these numbers So 1 ln x tends to 0 But rather slowly It s much bigger than 1 x p Oh I didn t mention that this exponent p is meant to be positive That s a convention that I m using without saying I should ve told you that So think x 1 2 x 1 x 2 they re all in this sort of moderate intermediate range And then that in turn goes to 0 but much more slowly then 1 e x also known as e x And that in turn this guy here goes to 0 incredibly fast e x 2 vanishes really really fast So this is a review of the L Hopital s Rule What we said last time and the application of it which is to rates of growth and tells us what these rates of growth are Today I want to talk about improper integrals And improper integrals we ve already really seen one or two of them on your exercises And we mention them a little bit briefly I m just going to go through them more carefully and more systematically now And we want to get just exactly what s going on with these rates of decay and their relationship with improper integrals So I need for you to understand on the spectrum of the range of functions like this which ones are suitable for integration as x goes to infinity Well let s start out with the definition The integral from a to infinity of f x dx is by definition the limit as n goes to infinity of the ordinary definite integral up to some fixed finite level That s the definition And there s a word that we use here which is that we say the integral so this is terminology for it converges if the limit exists And diverges if not Well these are the key words for today So here s the issue that we re going to be addressing Which is whether the limit exists or not In other words whether the integral converges or diverges These notions have a geometric analog which you should always be thinking of at the same time in the back of your head I ll draw a picture of the function Here it s starting out at a And maybe it s going down like this And it s interpreting it geometrically This would only work if f is positive Then the convergent case is the case where the area is finite So the total area is finite under this curve And the other case is the total area is infinite I claim that both of these things are possible Although this thing goes on forever if you stop it at one stage n then of course it s a finite number But as you go further and further and further there s more and more and more area And there are two possibilities Either as you go all the way out here to infinity the total that you get adds up to a finite total Or else maybe there s infinitely much For instance if it s a straight line going across there s clearly infinitely much area underneath So we need to do a bunch of examples And that s really our main job for the day and to make sure that we know exactly what to expect in all cases The first example is the integral from 0 to infinity of e kx dx Where k is going to be some positive number Some positive constant This is the most fundamental by far of the definite integrals Improper integrals And in order to handle this the thing that I need to do is to check the integral from 0 up to n e kx dx And since this is an easy integral to evaluate we re going to do it It s 1 k e kx that s the antiderivative Evaluated at 0 and n And that if I plug in these values is 1 k e k N Minus and if I evaluate it at 0 I get a 1 k e 0 So there s the answer And now we have to think about what happens as n goes to infinity So as n goes to infinity what s happening is the second term here stays unchanged But the first term is e to some negative power And the exponent is getting larger and larger That s because k is positive here You ve definitely got to pay attention Even though I m doing this with general variables here you ve got to pay attention to signs of things Because otherwise you ll always get the wrong answer So you have to pay very close attention here So this is if you like e minus infinity in the limit which is 0 And so in the limit this thing tends to 0 And this thing is just equal to 1 k And so all told the answer is 1 k And that s it Now we re going to abbreviate this a little bit This thought process you re going to have to go through every single time you do this But after a while you also get good enough at it that you can make it a little bit less cluttered So let me show you a shorthand for this same calculation Namely I write 0 to infinity e kx dx And that s equal to 1 k e kx 0 to infinity That was cute Not small enough however So here we are We have the same calculation as we had before But now we re thinking really in our minds that this infinity is some very very enormous number And we re going to plug it in And you can either do this in your head or not You say 1 k e infinity Here s where I ve used the fact that k is positive Because e k times a large number is minus infinity And then here 1 k 1 k Let me write it the same way I did before And that s just equal to 0 1 k which is what we want So this is the same calculation just slightly abbreviated Yeah Question STUDENT INAUDIBLE PROFESSOR Good question The question is what about the case when the limit is infinity I m distinguishing between something existing and its limit being infinity here Whenever I make a discussion of limits I say a finite limit or in this case it works for infinite limits So in other words when I say exists I mean exists and is finite So here when I say that it converges and I say the limit exists what I mean is that it s a finite number And so that s indeed what I said here The total area is finite And similarly over here I might add however that there is another part of this subject Which I m skipping entirely Which is a little bit subtle Which is the following If f changes sign there can be some cancellation and oscillation And then sometimes the limit exists but the total area if you counted it all positively is actually still infinite And we re going to avoid that case We re we re just going to treat these positive cases So don t worry about that for now That s the next layer of complexity which we re not addressing in this class Another question STUDENT INAUDIBLE PROFESSOR The question is would this be OK on tests The answer is absolutely yes I want to encourage you to do this If you can think about it correctly The subtle point is just you have to plug in infinity correctly Namely you have to realize that this only works if k is positive This is the step where you re plugging in infinity And I m letting you put this infinity up here as an endpoint value So in fact that s exactly the theme The theme is dealing with infinity here And I want you to be able to deal with it That s my goal STUDENT INAUDIBLE PROFESSOR OK so another question is so let s be sure here when the limit exists I say it has to be finite That means it s finite not infinite The limit can be 0 It can also be 1 It can be anything Doesn t have to be a positive number Other questions So we ve had our first example And now I just want to add one physical interpretation here This is Example 1 if you like And this is something that was on your problem set remember That we talked about the probability or the number if you like the number of particles on average that decay in some radioactive substance Say in time between 0 and some capital T And then that would be this integral 0 to capital T some total quantity times this integral here This is the typical kind of radioactive decay number that one gets Now in the limit so this is some number of particles If the substance is radioactive then in the limit we have this Which is equal to the total number of particles And that s something that s going to be important for normalizing and understanding How much does the whole substance how many moles do we have of this stuff What is it And so this is a number that is going to come up Now I emphasize that this notion of T going to infinity is just an idealization We don t really believe that we re going to wait forever for this substance to decay Nevertheless as theorists we write down this quantity And we use it All the time Furthermore there s other good reasons for using it and why physicists accept it immediately Even though it s not really completely physically realistic ever to let time go very very far into the future And the reason is if you notice this answer here look at how much simpler this number is 1 k than the numbers that I got in the intermediate stages here These are all ugly the limits are simple And this is a theme that I ve been trying to emphasize all semester Namely that the infinitesimal the things that you get when you do differentiation are the easier formulas The algebraic ones the things in the process of getting to the limit are the ugly ones These are the easy ones these are the hard ones So in fact infinity is basically easier than any finite number And a lot of appealing formulas come from those kinds of calculations Another question STUDENT INAUDIBLE PROFESSOR The question is shouldn t the answer be a Well the answer turns out to be a k Which means that when you set up your arithmetic and you model this to a collection of particles So you said it should be a But that s because you made an assumption Which was that a was the total number of particles But that s just false right This is the total number of particles So therefore if you want to set it up you want set up so that this number s the total number of particles And that s how you set up a model is you do all the calculations and you see what it s coming out to be And that s why you need to do this kind of calculation OK so The main thing is you shouldn t make assumptions about models You have to follow what the calculations tell you They re not lying OK so now We carried this out There s one other example which we talked about earlier in the class And I just wanted to mention it again It s probably the most famous after this one Namely the integral from minus infinity to infinity of e x 2 dx Which turns out amazingly to be able to be evaluated It turns out to be the square root of pi So this one is also great This is the constant which allows you to compute all kinds of things in probability So this is a key number in probability It basically is the key to understanding things like standard deviation and basically any other thing in the subject of probability It s also what s driving these polls that tell you within 4 accuracy we know that people are going to vote this way or that So in order to interpret all of those kinds of things you need to know this number And this number was only calculated numerically starting in the 1700s or so by people who actually by one guy whose name was de Moivre who was selling his services to various royalty who were running lotteries In those days they ran lotteries too And he was able to tell them what the chances were of the various games And he worked out this number He realized that this was the pattern Although he didn t know that it was the square root of pi he knew it to sufficient accuracy that he could tell them the correct answer to how much money their lotteries would make And of course we do this nowadays too In all kinds of ways Including slightly more legit businesses like insurance So now I I m going to give you some more examples And and the other examples are much more close to the edge between infinite and finite This distinction between convergence and divergence And let me just maybe I ll say one more word about why we care about this very gross issue of whether something is finite or infinite When you re talking about something like this normal curve here there s an issue of how far out you have to go before you can ignore the rest So we re going to ignore what s called the tail here Somehow you want to know that this is negligible And you want to know how negligible it is And this is the job of a mathematician is to know what finite region you have to consider and which one you re going to carefully calculate numerically And then the rest you re going to have to take care of by some theoretical reasoning You re going to have to know that these tails are small enough that they don t matter in your finite calculation And so we care very much about the tails Because they re the only thing that the machine won t tell us So that s the part that we have to know And these tails are also something which are discussed all the time in financial mathematics They re very worried about fat tails That is unlikely events that nevertheless happen sometimes And they get burned fairly regularly with them As they have recently with the mortgage scandal So these things are pretty serious and they really are spending a lot of time on them Of course there are lots of other practical issues besides just the mathematics But you ve got to get the math right too So we re going to now talk about some borderline cases for these fat tails Just how fat do they have to be before they become infinite and overwhelm the central bump So we ll save this for just a second And what I m saving up here is the borderline case which I m going to concentrate on which is this moderate rate which is x to powers Here s our next example I guess we ll call this Example 3 It s the integral from 1 to infinity dx x That s the power p 1 And this turns out to be a borderline case So it s worth carrying out carefully Now again I m going to do it by the slower method Rather than the shorthand method But ultimately you can do it by the short method if you d like I break it up into an integral that goes up to some large number n I see that its logarithm function is the antiderivative And so what I get is ln n ln 1 which is just 0 So this is just log n In any case it tends to infinity as n goes to infinity So the conclusion is since the limit is infinite that this thing diverges Now I m going to do this systematically now with all powers p to see what happens I ll look at the integral Sorry I m going to have to start at 1 here From 1 to infinity dx x p and see what happens with these And you ll see that p 1 is a borderline when I do this calculation This time I m going to do the calculation the hard way But now you re going to have to think and pay attention to see what it is that I m doing First of all I m going to take the antiderivative And this is x p so it s p 1 p 1 That s the antiderivative of the function 1 x p And then I have to evaluate that at 1 and infinity So now I ll write this down But I m going to be particularly careful here I ll write it down It s infinity to the p 1 p 1 so I plug in 1 here So I get 1 p 1 So this is what I m getting Again what you should be thinking here is this is a very large number to this power Now there are two cases There are two cases And they exactly split at p 1 When p 1 this number is 0 This exponent is 0 and in fact this expression doesn t make any sense because the denominator is also 0 But for all of the other values the denominator makes sense But what s going on is that this is infinite when this exponent is infinity to a positive power And it s 0 when it s infinity to a negative power So I m going to say it here and you must check this at home Because this is exactly what I m going to ask you about on the exam This is it This type of thing maybe with a specific value of p here When p lt 1 this thing is infinite On the other hand when p gt 1 this thing is 0 So when p gt 1 this thing is 0 It s just equal to 0 And so the answer is 1 p 1 Because that s this number Minus the quantity 1 p 1 This is a finite number here Notice that the answer would be weird if this thing went away in the p lt 1 case Then it would be a negative number It would be a very strange answer to this question So in fact that s not what happens What happens is that the answer doesn t make sense It s infinite So let me just write this down again under here This is a test in a particular case And here s the conclusion Ah No I m sorry I think I was going to write it over on this board here So the conclusion is that the integral from 1 to infinity dx x p diverges if p lt 1 And converges if p gt 1 And in fact we can actually evaluate it It s equal to 1 p 1 It s got a nice clean formula even Alright now let me remind you So I didn t spell the word diverges right did I Oh no that s an r I guess that s right Diverges if p lt 1 So really I needed both of these arguments which are sitting above it in order to do it Because the second argument didn t work at all when p 1 because the formula for the antiderivative is wrong The formula for the antiderivative is given by the ln function when p 1 So I had to do this calculation too This is the borderline case between p gt 1 and p lt 1 When p gt 1 we got convergence We could calculate the integral When p lt 1 when we got divergence and we calculated the integral over there And here in the borderline case we got a logarithm and we also got divergence So it failed at the edge Now this takes care of all the powers Now there are a number of different things that one can deduce from this And let me carry them out So this is more or less the second thing that you ll want to do And I m going to emphasize maybe one aspect of it I guess we ll get rid of this But it s still the issue that we re discussing here Is whether this area is fat or thin I ll remind you of that So here s the next idea Something called limit comparison Limit comparison is what you re going to use when instead of being able actually to calculate the number you don t yet know what the number is But you can make a comparison to something whose convergence properties you already understand Now here s the statement If a function f is similar to a function asymptotically the same as a function g as x goes to infinity I ll remind you what that means in a second Then the integral starting at some point out to infinity of f x dx and the other one converge and diverge at the same time So both either either sorry let s try it the other way Either both Either both converge or both diverge They behave exactly the same way In terms of whether they re infinite or not And let me remind you what this tilde means This thing means that f x g x tends to 1 So if you have a couple of functions like that then their behavior is the same This is more or less obvious It s just because far enough out this is for large a if you like We re not paying any attention to what happens It just has to do with the tail and after a while f x and g x are comparable to each other So their integrals are comparable to each other So let s just do a couple of examples here If you take the integral from 0 to infinity dx the square root of x 2 10 then I claim that the square root of x 2 10 resembles the square root of x 2 which is just x So this thing is going to be like So now I m going to have to do one thing to you here Which is I m going to change this to 1 To infinity dx x And the reason is that this x 0 is extraneous Doesn t have anything to do with what s going on with this problem This guy here the piece of it from so we re going to ignore the part integral from 0 to 1 dx square root of x 2 10 which is finite anyway And unimportant Whereas unfortunately the integral of dx will have a singularity at x 0 So we can t make the comparison there Anyway this one is infinite So this is divergence Using what I knew from before Yeah STUDENT INAUDIBLE PROFESSOR The question is why did we switch from 0 to 1 So I m going to say a little bit more about that later But let me just make it a warning here Which is that this guy here is infinite for other reasons Unrelated reasons The comparison that we are trying to make is with the tail as x goes to infinity So another way of saying this is that I should stick an a here and an a here and stay away from 0 So say a 1 If I make these both 1 that would be OK If I make them both 2 that would be OK If I make them both 100 that would be OK So let s leave it as 100 right now And it s acceptable I want you to stay away from the origin here Because that s another bad point And just talk about what s happening with the tail So this is a tail and I also had a different name for it up top Which is emphasizing this Which is limit comparison It s only what s happening at the very end of the picture that we re interested in So again this is as x goes to infinity That s the limit we re talking about the limiting behavior And we re trying not to pay attention to what s happening for small values of x So to be consistent if I m going to do it up to 100 I m ignoring what s happening up to the first 100 values In any case this guy diverged And let me give you another example This one you could have computed This one you could have computed right Because it s a square root of quadratic so there s a trig substitution that evaluates this one The advantage of this limit comparison method is it makes no difference whether you can compute the thing or not You can still decide whether it s finite or infinite fairly easily So let me give you an example of that So here we have another example We ll take the integral dx square root of x 3 3 Let s say for the sake of argument From 0 to infinity Let s leave off let s make it 10 to infinity whatever Now this one is problematic for you You re not going to be able to evaluate it I promise So on the other hand 1 the square root of x 3 3 is similar to 1 the square root of x 3 which is 1 x 3 2 So this thing is going to resemble this integral here Which is convergent According to our rule So those are the more or less the main ingredients Let me just mention one other integral which was the one that we had over here This one here If you look at this integral of course we can compute it so we know the area is finite But the way that you would actually carry this out if you didn t know the number and you wanted to check that this integral were finite then you would make the following comparison This one is not so difficult First of all you would write it as twice the integral from 0 to infinity of e x 2 dx This is a new example here and we re just checking for convergence only Not evaluation And now I m going to make a comparison here Rather than a limit comparison I m actually just going to make an ordinary comparison That s because this thing vanishes so fast It s so favorable that we can only put something on top of it we can t get something underneath it that exactly balances with it In other words this wiggle was something which had the same growth rate as the function involved This thing just vanishes incredibly fast It s great It s too good for us for this comparison So instead what I m going to make is the following comparison e x 2 lt e x At least for x gt 1 When x gt 1 then x 2 gt x and so x 2 lt x And so e x 2 is less than this So this is the reasoning involved And so what we have here is two pieces We have 2 the integral from 0 to 1 of e x 2 That s just a finite part And then we have this other part which I m going to replace with the e x here 2 times 1 to infinity e x dx So this is if you like this is ordinary comparison of integrals It s something that we did way at the beginning of the class Or much earlier on when we were dealing with integrals Which is that if you have a larger integrand then the integral gets larger So we ve replaced the integral We ve got the same integrand on 0 to 1 And we have a larger integrand on so this one is larger integrand And this one we know is finite This one is a convergent integral So the whole business is convergent But of course we replaced it by a much larger thing So we re not getting the right number out of this We re just showing that it converges So these are the main ingredients As I say once the thing gets really really fast decaying it s relatively straightforward There s lots of room to show that it converges Now there s one last item of business here which I have to promise you Which I promised you which had to do with dealing with this bottom piece here So I have to deal with what happens when there s a singularity This is known as an improper integral of the second type And the idea of these examples is the following You might have something like this Something like this Or something like this These are typical sorts of examples And before actually describing what happens I just want to mention So first of all the key point here is you can just calculate these things And plug in 0 and it works and you ll get the right answer So you ll determine you ll figure out that it turns out that this one will converge this one will diverge and this one will diverge That s what will turn out to happen However I want to warn you that you can fool yourself And so let me give you a slightly different example Let s consider this integral here The integral from 1 to 1 dx x 2 If you carry out this integral without thinking what will happen is you ll get the antiderivative which is x 1 evaluated at 1 and 1 And you plug it in And what do you get You get 1 1 1 uh oh 1 1 There s a lot of 1 s in this problem OK so that s 1 And this one if you work it all out as I sometimes don t get the signs right but this time I really paid attention It s 1 I m telling you that s what it is So that comes out to be 2 Now this is ridiculous This function here looks like this It s positive right 1 x 2 is positive How exactly is it that the area between 1 and 1 came out to be a negative number That can t be There was clearly something wrong with this And this is the kind of thing that you ll get regularly if you don t pay attention to convergence of integrals So what s going on here is actually that this area in here is infinite And this calculation that I made is nonsense So it doesn t work This is wrong Because it s divergent Actually when you get to imaginary numbers it ll turn out that there s a way of rescuing it But still it means something totally different when that integral is thought to be at 2 So What I want you to do here so I think we ll have to finish this up very briefly next time We ll do these three calculations and you ll see that these two guys are divergent and this one converges And we ll do that next time\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBYdqKgLhT93",
        "colab_type": "text"
      },
      "source": [
        "#Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQK0qK1kVYLn",
        "colab_type": "code",
        "outputId": "ae212c7f-1e62-4acd-a560-362dbe167449",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "train_shape = tuple(map(lambda x:x.shape,train.element_spec))\n",
        "test_shape = tuple(map(lambda x:x.shape,test.element_spec))\n",
        "#val_shape = tuple(map(lambda x:x.shape,val.element_spec))\n",
        "train_shape, test_shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((TensorShape([None]), TensorShape([])),\n",
              " (TensorShape([None]), TensorShape([])))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFGwV6ufa35-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = train.shuffle(BUFFER_SIZE)\n",
        "train_data = train_data.padded_batch(BATCH_SIZE, train_shape)\n",
        "test_data = test.padded_batch(BATCH_SIZE, test_shape)\n",
        "#val_data = test.padded_batch(BATCH_SIZE, val_shape)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVkiqdPHy2_s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "3e752e17-fef2-49e7-bcb5-34474582edc2"
      },
      "source": [
        "for example_batch, label_batch in train_data.take(2):\n",
        "  print(\"Batch shape:\", example_batch.shape)\n",
        "  print(\"label shape:\", label_batch.shape)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch shape: (8, 10795)\n",
            "label shape: (8,)\n",
            "Batch shape: (8, 12526)\n",
            "label shape: (8,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeC-XrzBg_PI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 4\n",
        "STEPS_PER_EPOCH = 5\n",
        "VALIDATION_STEPS = 1\n",
        "BATCH_SIZE = 8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nrr7LNo0hCTC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_m(model, epochs=EPOCHS):\n",
        "  model.compile(loss='binary_crossentropy',\n",
        "                optimizer='adam',\n",
        "                metrics=['accuracy'])\n",
        "  return model.fit(train_data, epochs=epochs,\n",
        "                      steps_per_epoch=STEPS_PER_EPOCH,\n",
        "                      validation_data=test_data,\n",
        "                      validation_steps=VALIDATION_STEPS\n",
        "                      )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2VWibcjhGSS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_accuracy_and_loss(history):\n",
        "  acc = history.history['accuracy']\n",
        "  val_acc = history.history['val_accuracy']\n",
        "\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "\n",
        "  plt.figure(figsize=(10, 10))\n",
        "  plt.subplot(2, 1, 1)\n",
        "  plt.plot(acc, label='Training Accuracy')\n",
        "  plt.plot(val_acc, label='Validation Accuracy')\n",
        "  plt.legend(loc='lower right')\n",
        "  plt.setp(plt.legend().get_texts(), color='black')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.ylim([min(plt.ylim()),1.0])\n",
        "  plt.title('Training and Validation Accuracy')\n",
        "\n",
        "  plt.subplot(2, 1, 2)\n",
        "  plt.plot(loss, label='Training Loss')\n",
        "  plt.plot(val_loss, label='Validation Loss')\n",
        "  plt.legend(loc='upper right')\n",
        "  plt.setp(plt.legend().get_texts(), color='black')\n",
        "  plt.ylabel('Cross Entropy')\n",
        "  plt.ylim([0.0,1.0])\n",
        "  plt.title('Training and Validation Loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooe_1jrsi5Ny",
        "colab_type": "code",
        "outputId": "f3f5404c-fff2-428d-ef11-e664c89424bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        }
      },
      "source": [
        "model = Sequential([\n",
        "    Embedding(encoder.vocab_size, 32, mask_zero=True),\n",
        "    Bidirectional(LSTM(64)),\n",
        "    Dense(1, activation='softmax')\n",
        "])\n",
        "model.summary()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 32)          560192    \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 128)               49664     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 609,985\n",
            "Trainable params: 609,985\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69W2NJNrLrnO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential([\n",
        "    Embedding(encoder.vocab_size, 32, mask_zero=True),\n",
        "    GRU(64),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QywKgTGZjLOb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 788
        },
        "outputId": "143c96ab-1f5a-4554-a9b8-16fbc9cf9486"
      },
      "source": [
        "history = train_m(model)\n",
        "plot_accuracy_and_loss(history)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 5 steps, validate for 1 steps\n",
            "Epoch 1/4\n",
            "5/5 [==============================] - 97s 19s/step - loss: 0.6896 - accuracy: 0.6000 - val_loss: 0.6856 - val_accuracy: 0.6250\n",
            "Epoch 2/4\n",
            "5/5 [==============================] - 98s 20s/step - loss: 0.6913 - accuracy: 0.5750 - val_loss: 0.6807 - val_accuracy: 0.6250\n",
            "Epoch 3/4\n",
            "5/5 [==============================] - 88s 18s/step - loss: 0.7016 - accuracy: 0.4500 - val_loss: 0.6813 - val_accuracy: 0.6250\n",
            "Epoch 4/4\n",
            "5/5 [==============================] - 80s 16s/step - loss: 0.6883 - accuracy: 0.5500 - val_loss: 0.6812 - val_accuracy: 0.6250\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmEAAAJcCAYAAACxEXM4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLwqLL2cAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqwGtevYzpRy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}